{"docs":[{"location":"/paradox.json","text":"","title":""},{"location":"/index.html","text":"","title":"endpoints4s"},{"location":"/index.html#endpoints4s","text":"endpoints4s is a Scala library for remote communication. It ensures that HTTP servers, HTTP clients, and documentation always agree on the same protocol.\nmaintenance is simplified: the API documentation is automatically updated when an endpoint is modified ; errors are raised at compile-time if endpoints are invoked with incompatible parameters.\nServers, clients and documentation are all derived from a single source of truth describing the underlying protocol details (e.g., which verb, path, query parameters, headers, authentication strategy, etc. to use). For instance, here is an endpoint for incrementing a counter. It uses the HTTP verb POST, the URL path /increment, a JSON request entity containing an Increment value, and it returns an empty response.\ncopysourceval increment: Endpoint[Increment, Unit] =\n  endpoint(\n    post(path / \"increment\", jsonRequest[Increment]),\n    ok(emptyResponse)\n  )\nFrom the client perspective, calling an HTTP endpoint is as simple as calling a function:\ncopysourceval eventuallyDone: Future[Unit] = increment(Increment(step = 42)).future\nConversely, from the server perspective implementing an HTTP endpoint is as simple as implementing a function:\ncopysourceincrement.implementedBy(inc => counter.single += inc.step)\nendpoints4s takes care of constructing the HTTP requests and responses and decoding the server responses or client requests into high-level data types according to the endpoint descriptions.\nIn contrast with most other approaches, endpoints4s is a pure, “vanilla”, Scala library. No code generation. No macros. IDE friendly. Endpoint descriptions are first-class Scala values, which can be reused, combined, and abstracted over.\nThe library currently supports the following backends:\nclients: Pekko HTTP, Akka HTTP, http4s, Play-WS, sttp, scalaj, XMLHttpRequest (Scala.js), and Fetch (Scala.js) ; servers: Pekko HTTP, Akka HTTP, http4s, and Play ; documentation: OpenAPI ; JSON is supported via Circe, Play-Json, or ujson ;\n… but the library is designed to be extensible, anyone can:\nimplement a new interpreter for the existing endpoint descriptions (e.g. generation of RAML documentation, finch client and server backend, etc.) ; add new descriptions to the existing ones (e.g. to define an application-specific authentication strategy).","title":"endpoints4s"},{"location":"/index.html#getting-started","text":"Have a look at the quick start guide to understand in a few minutes what the library does and how to setup a project ; Check out the use cases to know the typical problems that endpoints4s addresses ; Browse the API documentation or the samples.","title":"Getting started"},{"location":"/index.html#contributing","text":"See the Github repository.","title":"Contributing"},{"location":"/index.html#sponsors","text":"Bestmile supports engineering work on the project.","title":"Sponsors"},{"location":"/use-cases.html","text":"","title":"Use Cases"},{"location":"/use-cases.html#use-cases","text":"This page shows typical use cases where endpoints4s can provide value.","title":"Use Cases"},{"location":"/use-cases.html#microservices","text":"Describe the HTTP APIs between the services, and let endpoints4s implement the clients and servers for these APIs:\ncopysource/** Application of a command.\n  *\n  * Returns the produced event, or `None` in case of failure (aggregate\n  * not found or invalid command).\n  */\nval command: Endpoint[Command, Option[StoredEvent]] =\n  endpoint(\n    post(path / \"command\", jsonRequest[Command]),\n    ok(jsonResponse[Option[StoredEvent]])\n  )\nInvoking a service from another is as simple as a method call:\ncopysourceval eventuallyMaybeEvent: IO[Option[StoredEvent]] =\n  commandsClient.command.sendAndConsume(CreateMeter(createData.label))\nendpoints4s takes care of correctly constructing the HTTP request and decoding the HTTP response according to the endpoint description.\nMaintenance effort is reduced: you only maintain the description of the HTTP API, not its client and server implementations.","title":"Microservices"},{"location":"/use-cases.html#web-applications","text":"Thanks to Scala.js it is possible to write the client-side part of a web application in Scala. Then, endpoints4s simplifies client-server communication by turning method calls into remote invocations.\nExample of endpoint definition:\ncopysource/** Registers a new meter */\nval createMeter: Endpoint[CreateMeter, Meter] =\n  endpoint(\n    post(metersPath, jsonRequest[CreateMeter]),\n    ok(jsonResponse[Meter])\n  )\nCorresponding invocation from the client-side:\ncopysourceval eventuallyCreatedMeter: Future[Meter] =\n  PublicEndpoints.createMeter(CreateMeter(name)).future","title":"Web Applications"},{"location":"/use-cases.html#documenting-a-web-service","text":"Thanks to the separation between the description of an HTTP API and its implementation, endpoints4s can also generate an OpenAPI document for a given HTTP API description.\nFor instance, given the following endpoints descriptions:\ncopysourceimport endpoints4s.{algebra, generic}\n\ntrait CounterEndpoints\n    extends algebra.Endpoints\n    with algebra.JsonEntitiesFromSchemas\n    with generic.JsonSchemas {\n\n  // HTTP endpoint for querying the current value of the counter. Uses the HTTP\n  // verb ''GET'' and the path ''/counter''. Returns the current value of the counter\n  // in a JSON object. (see below for the `counterJson` definition)\n  val currentValue: Endpoint[Unit, Counter] =\n    endpoint(get(path / \"counter\"), counterJsonResponse)\n\n  // HTTP endpoint for updating the value of the counter. Uses the HTTP verb ''POST''\n  // and the path ''/counter''. The request entity contains an `Operation` object encoded\n  // in JSON. The endpoint returns the current value of the counter in a JSON object.\n  val update: Endpoint[Operation, Counter] = endpoint(\n    post(\n      path / \"counter\",\n      jsonRequest[Operation],\n      docs = Some(\"The operation to apply to the counter\")\n    ),\n    counterJsonResponse\n  )\n\n  // Since both the `currentValue` and `update` endpoints return the same\n  // information, we define it once and just reuse it. Here, we say\n  // that they return an HTTP response whose entity contains a JSON document\n  // with the counter value\n  lazy val counterJsonResponse: Response[Counter] =\n    ok(jsonResponse[Counter], docs = Some(\"The counter current value\"))\n\n  // We generically derive a data type schema. This schema\n  // describes that the case class `Counter` has one field\n  // of type `Int` named “value”\n  implicit lazy val jsonSchemaCounter: JsonSchema[Counter] = genericJsonSchema\n\n  // Again, we generically derive a schema for the `Operation`\n  // data type. This schema describes that `Operation` can be\n  // either `Set` or `Add`, and that `Set` has one `Int` field\n  // name `value`, and `Add` has one `Int` field named `delta`\n  implicit lazy val jsonSchemaOperation: JsonSchema[Operation] =\n    genericJsonSchema\n\n}\nendpoints4s can produce the following OpenApi document.","title":"Documenting a Web Service"},{"location":"/quick-start.html","text":"","title":"Quick start"},{"location":"/quick-start.html#quick-start","text":"The central idea of endpoints4s is that you first define an abstract description of your HTTP endpoints and then the library provides:\na server implementation decoding requests and building responses, a client implementation building requests and decoding responses, a machine readable documentation (OpenAPI document).","title":"Quick start"},{"location":"/quick-start.html#project-layout","text":"The typical setup consists in a multi-project build, with a client project and a server project both depending on a shared project.\nThe shared project contains the description of the communication protocol. The server project implements this communication protocol. The client project uses the protocol to communicate with the server.","title":"Project layout"},{"location":"/quick-start.html#dependencies","text":"The shared project has to depend on so-called algebras, which provide the vocabulary to describe the communication endpoints, and the client and server projects have to depend on interpreters, which give a concrete meaning to the endpoint descriptions. See the algebras and interpreters page for an exhaustive list.\nIn this example you will use the following dependencies:\nval shared =\n  crossProject(JSPlatform, JVMPlatform).crossType(CrossType.Pure).settings(\n    libraryDependencies ++= Seq(\n      \"org.endpoints4s\" %%% \"algebra\" % \"1.11.0\",\n      // optional, see explanation below\n      \"org.endpoints4s\" %%% \"json-schema-generic\" % \"1.11.0\"\n    )\n  )\n\nval sharedJS = shared.js\nval sharedJVM = shared.jvm\n\nval client =\n  project.enablePlugins(ScalaJSPlugin).settings(\n    libraryDependencies += \"org.endpoints4s\" %%% \"fetch-client\" % \"3.2.0\"\n  ).dependsOn(sharedJS)\n\nval server =\n  project.settings(\n    libraryDependencies ++= Seq(\n      \"org.endpoints4s\" %% \"pekko-http-server\" % \"1.0.0\",\n      \"org.apache.pekko\" %% \"pekko-stream\" % \"1.0.1\",\n      \"org.scala-stm\" %% \"scala-stm\" % \"0.8\"\n    )\n  ).dependsOn(sharedJVM)\nThe shared project uses the json-schema-generic module in addition to the required algebra interface algebra, to define the communication endpoints and to automatically derive the JSON schemas of the entities from their Scala type definitions.\nThe client project uses a Scala.js web (Fetch) client interpreter.\nFinally, the server project uses a server interpreter backed by Pekko HTTP. It also uses the scala-stm library for implementing the business logic.","title":"Dependencies"},{"location":"/quick-start.html#description-of-the-http-endpoints","text":"In the shared project, define a CounterEndpoints trait describing two endpoints, one for getting a counter value and one for incrementing it:\ncopysourceimport endpoints4s.{algebra, generic}\n\n/** Defines the HTTP endpoints description of a web service implementing a counter.\n  * This web service has two endpoints: one for getting the current value of the counter,\n  * and one for incrementing it.\n  */\ntrait CounterEndpoints\n    extends algebra.Endpoints\n    with algebra.JsonEntitiesFromSchemas\n    with generic.JsonSchemas {\n\n  /** Get the counter current value.\n    * Uses the HTTP verb “GET” and URL path “/current-value”.\n    * The response entity is a JSON document representing the counter value.\n    */\n  val currentValue: Endpoint[Unit, Counter] =\n    endpoint(get(path / \"current-value\"), ok(jsonResponse[Counter]))\n\n  /** Increments the counter value.\n    * Uses the HTTP verb “POST” and URL path “/increment”.\n    * The request entity is a JSON document representing the increment to apply to the counter.\n    * The response entity is empty.\n    */\n  val increment: Endpoint[Increment, Unit] =\n    endpoint(\n      post(path / \"increment\", jsonRequest[Increment]),\n      ok(emptyResponse)\n    )\n\n  // Generically derive the JSON schema of our `Counter`\n  // and `Increment` case classes defined thereafter\n  implicit lazy val counterSchema: JsonSchema[Counter] = genericJsonSchema\n  implicit lazy val incrementSchema: JsonSchema[Increment] = genericJsonSchema\n\n}\n\ncase class Counter(value: Int)\ncase class Increment(step: Int)\nThe currentValue and increment members define the endpoints for getting the counter current value or incrementing it, as their names suggest. The counterSchema and incrementSchema members define a JSON schema that will be used to serialize and deserialize the request and response entities.","title":"Description of the HTTP endpoints"},{"location":"/quick-start.html#client-implementation","text":"A client implementation of the endpoints can be obtained by mixing so-called “interpreters” to the CounterEndpoints trait defined above. In this example, you want to get a JavaScript (Scala.js) client that uses Fetch under the hood. Defines the following CounterClient object in the client project:\ncopysourceimport endpoints4s.fetch\nimport endpoints4s.fetch.EndpointsSettings\n\n/** Defines an HTTP client for the endpoints described in the `CounterEndpoints` trait.\n  * The derived HTTP client uses XMLHttpRequest to perform requests and returns\n  * results in a `js.Thenable`.\n  */\nobject CounterClient\n    extends CounterEndpoints\n    with fetch.thenable.Endpoints\n    with fetch.JsonEntitiesFromSchemas {\n  lazy val settings: EndpointsSettings = EndpointsSettings()\n}\nAnd then, the CounterClient object can be used as follows:\ncopysourceimport scala.scalajs.js\n\n/** Performs an XMLHttpRequest on the `currentValue` endpoint, and then\n  * deserializes the JSON response as a `Counter`.\n  */\nval eventuallyCounter: js.Thenable[Counter] = CounterClient.currentValue(()).thenable\nAnd also:\ncopysource/** Serializes the `Increment` value into JSON and performs an XMLHttpRequest\n  * on the `increment` endpoint.\n  */\nval eventuallyDone: js.Thenable[Unit] = CounterClient.increment(Increment(42)).thenable\nAs you can see, invoking an endpoint consists of calling a function on the CounterClient object. endpoints4s then builds an HTTP request (according to the endpoint description), sends it to the server, and eventually decodes the HTTP response (according to the endpoint description).","title":"Client implementation"},{"location":"/quick-start.html#server-implementation","text":"Similarly, a server implementation of the endpoints can be obtained by mixing the appropriate interpreters to the CounterEndpoints trait. In this example, you want to get a JVM server that uses Pekko HTTP under the hood. Create the following CounterServer class in the server project:\ncopysourceimport org.apache.pekko.http.scaladsl.server.Directives._\nimport org.apache.pekko.http.scaladsl.server.Route\nimport endpoints4s.pekkohttp.server\n\nimport scala.concurrent.stm.Ref\n\n/** Defines a Play router (and reverse router) for the endpoints described\n  * in the `CounterEndpoints` trait.\n  */\nobject CounterServer\n    extends CounterEndpoints\n    with server.Endpoints\n    with server.JsonEntitiesFromSchemas {\n\n  /** Simple implementation of an in-memory counter */\n  val counter = Ref(0)\n\n  // Implements the `currentValue` endpoint\n  val currentValueRoute =\n    currentValue.implementedBy(_ => Counter(counter.single.get))\n\n  // Implements the `increment` endpoint\n  val incrementRoute =\n    increment.implementedBy(inc => counter.single += inc.step)\n\n  val routes: Route =\n    currentValueRoute ~ incrementRoute\n\n}\nThe routes value produced by endpoints4s is a Route value directly usable by Pekko HTTP. The last section shows how to setup an Pekko HTTP server that uses these routes.\nThe routes implementations provided by endpoints4s decode the incoming HTTP requests, call the corresponding logic (here, incrementing the counter or getting its current value), and build the HTTP responses.","title":"Server implementation"},{"location":"/quick-start.html#documentation-generation","text":"You can also generate documentation for the endpoints, again by mixing the appropriate interpreters. Create the following CounterDocumentation object in the server project:\ncopysourceimport endpoints4s.openapi\nimport endpoints4s.openapi.model.{Info, OpenApi}\n\n/** Generates OpenAPI documentation for the endpoints described in the `CounterEndpoints` trait.\n  */\nobject CounterDocumentation\n    extends CounterEndpoints\n    with openapi.Endpoints\n    with openapi.JsonEntitiesFromSchemas {\n\n  val api: OpenApi =\n    openApi(\n      Info(title = \"API to manipulate a counter\", version = \"1.0.0\")\n    )(currentValue, increment)\n\n}\nThis code defines a CounterDocumentation object with an api member containing an OpenAPI object documenting the currentValue and increment endpoints.","title":"Documentation generation"},{"location":"/quick-start.html#running-the-application","text":"Finally, to run your application you need to build a proper Pekko HTTP server serving your routes. Define the following Main object:\ncopysourceimport org.apache.pekko.actor.ActorSystem\nimport org.apache.pekko.http.scaladsl.Http\nimport org.apache.pekko.http.scaladsl.server.Directives._\n\nobject Main extends App {\n  implicit val system: ActorSystem = ActorSystem(\"server-system\")\n  val routes = CounterServer.routes ~ DocumentationServer.routes\n  Http().newServerAt(\"0.0.0.0\", 8000).bindFlow(routes)\n}\n\n// Additional route for serving the OpenAPI documentation\nimport endpoints4s.openapi.model.OpenApi\nimport endpoints4s.pekkohttp.server\n\nobject DocumentationServer\n    extends server.Endpoints\n    with server.JsonEntitiesFromEncodersAndDecoders {\n\n  val routes =\n    endpoint(get(path / \"documentation.json\"), ok(jsonResponse[OpenApi]))\n      .implementedBy(_ => CounterDocumentation.api)\n\n}\nYou can then browse the http://localhost:8000/current-value URL to query the counter value, or the http://localhost:8000/documentation.json URL to get the generated OpenAPI documentation, which should look like the following:\n{\n  \"openapi\": \"3.0.0\",\n  \"info\": {\n    \"title\": \"API to manipulate a counter\",\n    \"version\": \"1.0.0\"\n  },\n  \"components\": {\n    \"schemas\": {\n      \"quickstart.Counter\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"value\": {\n            \"format\": \"int32\",\n            \"type\": \"integer\"\n          }\n        },\n        \"required\": [\"value\"]\n      },\n      \"quickstart.Increment\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"step\": {\n            \"format\": \"int32\",\n            \"type\": \"integer\"\n          }\n        },\n        \"required\": [\"step\"]\n      },\n      \"endpoints.Errors\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        }\n      }\n    }\n  },\n  \"paths\": {\n    \"/increment\": {\n      \"post\": {\n        \"requestBody\": {\n          \"content\": {\n            \"application/json\": {\n              \"schema\": {\n                \"$ref\": \"#/components/schemas/quickstart.Increment\"\n              }\n            }\n          }\n        },\n        \"responses\": {\n          \"400\": {\n            \"description\": \"Client error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/endpoints.Errors\"\n                }\n              }\n            }\n          },\n          \"500\": {\n            \"description\": \"Server error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/endpoints.Errors\"\n                }\n              }\n            }\n          },\n          \"200\": {\n            \"description\": \"\"\n          }\n        }\n      }\n    },\n    \"/current-value\": {\n      \"get\": {\n        \"responses\": {\n          \"400\": {\n            \"description\": \"Client error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/endpoints.Errors\"\n                }\n              }\n            }\n          },\n          \"500\": {\n            \"description\": \"Server error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/endpoints.Errors\"\n                }\n              }\n            }\n          },\n          \"200\": {\n            \"description\": \"\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/quickstart.Counter\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}","title":"Running the application"},{"location":"/quick-start.html#next-step","text":"Learn about the design principles of the endpoints library.","title":"Next Step"},{"location":"/design.html","text":"","title":"Design in a nutshell"},{"location":"/design.html#design-in-a-nutshell","text":"You have seen in the quick start page that using the endpoints library consists in first defining abstract descriptions of HTTP endpoints, and then producing clients, servers, or documentation, by interpreting these descriptions. This page takes a step back to explain the underlying architecture of the library, and then provides some guidelines to embrace this design.","title":"Design in a nutshell"},{"location":"/design.html#descriptions-and-interpretations","text":"Here is an example of endpoint description:\ncopysourceimport endpoints4s.{algebra, generic}\n\ntrait CounterEndpoints\n    extends algebra.Endpoints\n    with algebra.JsonEntitiesFromSchemas\n    with generic.JsonSchemas {\n\n  val currentValue: Endpoint[Unit, Counter] =\n    endpoint(get(path / \"current-value\"), ok(jsonResponse[Counter]))\n\n}\nEndpoint descriptions are defined in terms of operations (e.g., endpoint, get, path, ok, etc.) provided by traits living in the `endpoints4s.algebra` package. These operations are all abstract. Furthermore, their return types are also abstract. Their purpose is only to define the rules for constructing and combining parts of HTTP endpoint descriptions. This is why they are called “algebra interfaces”, or just algebras.\nFor instance, consider the following truncated version of the `Endpoints` algebra:\npackage endpoints4s.algebra\n\ntrait Endpoints {\n  /** A request that uses the method GET and the given URL */\n  def get[A](url: Url[A]): Request[A]\n\n  /** A request that carries an `A` information */\n  type Request[A]\n  /** An URL that carries an `A` information */\n  type Url[A]\n}\nHere, the get method provides a way to define an HTTP request description from a URL description.\nNote Since the Request[A] type is abstract, the only way to construct a value of that type is by calling a method that returns a Request[A], such as the method get, in the above code. For this reason, we say that the method get is a constructor for Request[A].\nThe Request[A] type models an HTTP request that carries an information of type A. From a client point of view, this A is what is needed to build a Request[A]. Conversely, from a server point of view, this A is what is provided by an incoming a Request[A].\nYou have seen in the “quick start” page that interpreters give semantics to the algebras. They do so by fixing their type members and implementing their methods accordingly. For instance, here is the semantics given to Request[A] by the Scala.js client interpreter:\npackage endpoints4s.xhr\n\ntrait Endpoints extends endpoints4s.algebra.Endpoints {\n  type Request[A] = js.Function1[A, XMLHttpRequest]\n}\nAs previously said, from a client point of view we want to send requests and get responses. So, Request[A] has the semantics of a function that builds an XMLHttpRequest out of an A value.\nHere is the semantics given by the Play-based server interpreter:\npackage endpoints4s.play.server\n\ntrait Endpoints extends endpoints4s.algebra.Endpoints {\n  type Request[A] = RequestHeader => Option[BodyParser[A]]\n}\nThe aim of the endpoints4s.play.server.Endpoints trait is to provide a Play router for a given set of HTTP endpoints. So, a Request[A] is a function that checks if an incoming request matches this endpoint, and in such a case it returns a BodyParser[A] that decodes a value of type A from the request.\nAs you can see, each interpreter brings its own concrete semantic type for Request[A]. Client interpreters typically fix the Request[A] type to a function that takes an A as parameter. Conversely, server interpreters typically fix the Request[A] type to a function that returns an A. Can you guess what documentation interpreters do with this type parameter A? You can see the answer here. It is discarded because this type A models the information that is carried by an actual request, at run-time, but the documentation is static (so, there is no A value to deal with).\nNote This technique has been described in details by Bruno C. d. S. Oliveira et al. [1]. Note that we use a variant discovered by Christian Hofer et al. [2], which uses type members rather than type parameters.","title":"Descriptions and Interpretations"},{"location":"/design.html#algebras-summary","text":"Algebras are traits that provide abstract type members and methods defining how to construct and combine endpoint descriptions.\nInterpreters are traits that extend algebras, and give them a concrete meaning by fixing their type members and implementing their methods accordingly.","title":"Algebras Summary"},{"location":"/design.html#modular-algebras","text":"The separation between descriptions and interpretations provides one dimension of modularity: a same endpoint description can be interpreted with a client interpreter, a server interpreter, or documentation interpreter. Even more, the client and server stacks can be completely different (one can use Play framework while the other uses Pekko, for instance). Here is a diagram illustrating the fact that multiple interpreters can be applied to a same algebra:\nNote From that perspective, endpoint descriptions are equivalent to protobuf or Swagger files: they are machine-readable descriptors for a service. As a consequence, if you want to share a descriptor of your service with the outside world, one option is to publish the artifact containing the traits that provide your endpoint descriptions. Downstream users will then be able to turn these descriptions to a client of their choice by applying the interpreter of their choice. Of course, this works only if your users use Scala. For the rest of the world, you can distribute the descriptor produced by the OpenAPI interpreter.\nThe fact that algebras are defined in traits and that we can mix several traits together provides a second dimension of modularity: the algebra itself is modular. For instance, you have seen in the code example at the top of this page that two algebras were used together: algebra.Endpoints and algebra.JsonEntitiesFromSchemas. The diagram below shows a couple of algebras and their relations:\nWe say that the BasicAuthentication algebra enriches the Endpoints algebra with operations related to authentication.\nThe fact that algebras are modular is a double-edged sword. On one hand, having several algebra modules makes it possible for some interpreters to support only a subset of them. Consider for instance an algebra for describing Web Sockets. Not all HTTP clients or servers have a good support of Web Sockets, which means that not all HTTP clients or servers could interpret such an algebra. However, this is not a problem: that algebra module can be skipped, and the interpreters can focus on supporting only the modules that are relevant to them. Another benefit is that the algebras provided by the endpoints library can be extended outside of the library itself. Any application-specific concern can be introduced as another algebra without having to make the endpoints library aware of it. This point is illustrated in the authentication example.\nOn the other hand, a modular algebra means that you have to select the algebra modules to use before you can write endpoint descriptions. For instance, the provided Endpoints algebra is minimalist and is unlikely to be enough for your needs. Most probably, you will complete it with one of the JsonEntities algebras. Once you have settled on the algebra modules you want to use, you will have to find the matching interpreter modules. In general, interpreters follow a specific naming convention that should make this process easier.\nAnother consequence of the modularity of the algebras is that the library intentionally provides a minimal set of features. The aim is to cover most users’ needs in the main algebra, and let the community experiment with other algebra modules on their own before considering including them into the main algebra.","title":"Modular Algebras"},{"location":"/design.html#summary","text":"Algebras are modular. You select the algebras that provide the features you need, and you can even create your own algebras for more specific needs. The more algebras are used, the less interpreters can interpret them.","title":"Summary"},{"location":"/design.html#next-step","text":"Discover the hierarchy of algebras.\n[1] B. C. d. S. Oliveira et. al. Extensibility for the Masses, Practical Extensibility with Object Algebras, ECOOP, 2012 (pdf) [2] C. Hofer et al. Polymorphic Embedding of DSLs, GPCE, 2008 (pdf)","title":"Next Step"},{"location":"/algebras-and-interpreters.html","text":"","title":"Algebras and interpreters"},{"location":"/algebras-and-interpreters.html#algebras-and-interpreters","text":"In endpoints4s, we call “algebra interfaces” (or just algebras) the traits that provide methods for constructing and combining descriptions of endpoints. You can find more details about the design of these algebras in the Design in a nutshell page.\nThe concepts defined by algebras are given a concrete meaning by interpreters. In practice, we have three kinds of interpreters:\nclients building requests (their URL, headers and entity) and decoding responses, servers decoding requests and building responses, documentation in a machine-readable format.","title":"Algebras and interpreters"},{"location":"/algebras-and-interpreters.html#naming-conventions","text":"algebras are defined as traits in the endpoints4s.algebra package ; e.g. the `endpoints4s.algebra.Urls` trait defines an algebra for describing URLs. algebras’ dependencies can be found in their super types ; interpreters are traits that have the same name as the algebra they implement (they can be found by looking at the “known subclasses” of an algebra, in the Scaladoc) ; e.g. the `endpoints4s.http4s.client.Urls` trait defines an http4s-based interpreter for the Urls algebra. compatible interpreters are in the same package ; e.g. the `endpoints4s.http4s.client` package provides client interpreters that are all based on http4s under the hood.","title":"Naming conventions"},{"location":"/algebras-and-interpreters.html#matching-algebras-and-interpreters","text":"To define endpoint descriptions you need to select which algebras you need. For instance:\nimport endpoints4s.algebra\n\ntrait MyCustomAlgebra extends algebra.Endpoints\n  with algebra.JsonEntitiesFromSchemas\n  with algebra.BasicAuthentication\nThen, to interpret the endpoint descriptions you need to build an interpreter that matches this algebra. By following the aforementioned naming conventions, you should be looking for all the traits that have the same names as your algebra modules and that are in the package of the interpreter you want to use. For instance, to build an Pekko-HTTP server:\nimport endpoints4s.pekkohttp.server\n\ntrait MyPekkoHttpServer extends MyCustomAlgebra\n  with server.Endpoints\n  with server.JsonEntitiesFromSchemas\n  with server.BasicAuthentication\nWarning If you try to mix an interpreter module that doesn’t match your algebra the compiler will raise “conflicting inherited members” errors.","title":"Matching Algebras and Interpreters"},{"location":"/algebras-and-interpreters.html#algebras","text":"Algebras form a hierarchy: it is possible to extend an algebra with additional vocabulary, or to mix several algebras together to merge their vocabulary. This hierarchy can be seen in the diagram generated by the API documentation.\nThe following table lists the available algebras and points to their documentation. You should start by reading the documentation of the Endpoints algebra, and the documentation of the JsonEntities and JsonSchemas algebras if you want to work with JSON.\nName Description Endpoints HTTP endpoints JsonEntities JSON request and response entities JsonSchemas JSON schemas of data types ChunkedEntities Streamed requests and responses Assets Asset segments, endpoints serving fingerprinted assets MuxEndpoints Multiplexed HTTP endpoints","title":"Algebras"},{"location":"/algebras-and-interpreters.html#interpreters","text":"Interpreters give a concrete meaning to the vocabulary and operations provided by the algebras. They usually rely on other libraries (e.g. circe, Pekko HTTP, etc.) to do so. Pick the interpreters that fit your existing stack!\nFamily Description Pekko HTTP Client and server backed by Pekko HTTP Akka HTTP Client and server backed by Akka HTTP http4s Client and server backed by http4s Play framework Client and server backed by Play framework Scala.js web (Fetch) Scala.js web client using Fetch Scala.js web (XHR) Scala.js web client using XMLHttpRequest scalaj-http JVM client backed by scalaj-http sttp JVM client backed by sttp OpenAPI Generates OpenAPI documents for endpoints definitions circe Builds circe codecs out of JSON schema definitions Play JSON Builds Play JSON Reads and Writes out of JSON schema definitions\nNote You can have different stacks on the client-side and the server-side. For instance, you can have a server backed by Play framework, a client backed by Pekko HTTP, and another client backed by Scala.js (for web browsers).","title":"Interpreters"},{"location":"/algebras/endpoints.html","text":"","title":"Endpoints"},{"location":"/algebras/endpoints.html#endpoints","text":"This algebra, at the top of the hierarchy, provides the base vocabulary to describe HTTP endpoints, requests and responses.\nAPI documentation","title":"Endpoints"},{"location":"/algebras/endpoints.html#endpoint","text":"The algebra introduces the concept of Endpoint[A, B]: an HTTP endpoint whose request carries an information of type A and whose response carries an information of type B. For instance, an endpoint of type Endpoint[Long, Option[User]] has a request containing a Long (for instance, a user id), and a response optionally containing a User.\nYou can define an endpoint by using the endpoint constructor:\ncopysource// An endpoint whose requests use the HTTP verb “GET” and the URL\n// path “/some-resource”, and whose responses have an entity of\n// type “text/plain”\nval someResource: Endpoint[Unit, String] =\n  endpoint(get(path / \"some-resource\"), ok(textResponse))\nThe endpoint constructor takes two parameters, the request description (of type Request[A]) and the response description (of type Response[B]), which are documented in the following sections.\nIt also takes optional parameters carrying documentation information:\ncopysourceendpoint(\n  get(path / \"some-resource\"),\n  ok(textResponse),\n  docs = EndpointDocs().withDescription(Some(\"The contents of some resource\"))\n)","title":"Endpoint"},{"location":"/algebras/endpoints.html#request","text":"The Request[A] type models an HTTP request carrying some information of type A. For instance, a Request[Long] value is a request containing a Long value.\nA request is defined in terms of an HTTP verb, an URL, an entity and headers:\ncopysource// A request that uses the verb “GET”, the URL path “/foo”,\n// no entity, no documentation, and no headers\nrequest(Get, path / \"foo\", emptyRequest, None, emptyRequestHeaders)\nFor convenience, get, post, put and delete methods are provided:\ncopysourceget(path / \"foo\") // Same as above\nThe next sections document how to describe URLs, request headers and request entities.","title":"Request"},{"location":"/algebras/endpoints.html#url","text":"The Url[A] type models an URL carrying some information of type A. For instance, an Url[Long] value is an URL containing a Long value.\nAn URL is defined by a path and a query string. Here are some self-explanatory examples of URLs:\ncopysource// the root path: “/”\npath\n// static segment: “/users”\npath / \"users\"\n// path with trailing slash: “/users/”\npath / \"users\" / \"\"\n// path parameter: “/users/1234”, “/users/5678”, …\npath / \"users\" / segment[Long]()\n// path parameter: “/assets/images/logo.png”\npath / \"assets\" / remainingSegments()\n// query parameter: “/articles?page=2”, “/articles?page=5”, …\npath / \"articles\" /? qs[Int](\"page\")\n// optional parameter: “/articles”, “/articles?page=2”, …\npath / \"articles\" /? qs[Option[Int]](\"page\")\n// repeated parameter: “/articles?kinds=garden&kinds=woodworking”, …\npath / \"articles\" /? qs[List[String]](\"kinds\")\n// several parameters: “/?q=foo&lang=en”, …\npath /? (qs[String](\"q\") & qs[String](\"lang\"))\nThe examples above show that basic types (e.g., Int, String, etc.) are supported out of the box as query and path parameters. A user-defined type T can be supported either by\ndefining implicit instances of Segment[T] (for path parameters) or QueryStringParam[T] (for query string parameters), transforming or refining already supported types by using xmap or xmapPartial (see next section).\nPath segments and query string parameters can take additional parameters containing documentation:\ncopysource// “/users/{id}”\npath / \"users\" / segment[Long](\"id\", docs = Some(\"A user id\"))\n\n// “/?q=foo&lang=en”, …\nval query = qs[String](\"q\", docs = Some(\"Query\"))\nval lang = qs[String](\"lang\", docs = Some(\"Language\"))\npath /? (query & lang)","title":"URL"},{"location":"/algebras/endpoints.html#transforming-and-refining-url-constituents","text":"All the data types involved in a URL description (Path[A], Segment[A], QueryString[A], etc.) have an xmap and an xmapPartial operations, for transforming or refining their carried type.\nFor instance, consider the following user-defined Location type, containing a longitude and a latitude:\ncopysourcecase class Location(longitude: Double, latitude: Double)\nThe QueryString[Location] type means “a query string that carries a Location”. We can define a value of type QueryString[Location] by transforming a query string that carries the longitude and latitude parameters as follows:\ncopysourceval locationQueryString: QueryString[Location] =\n  (qs[Double](\"lon\") & qs[Double](\"lat\")).xmap { case (lon, lat) =>\n    Location(lon, lat)\n  } { location => (location.longitude, location.latitude) }\nThe xmap operation requires the source type and the target type to be equivalent (in the above case, the source type is (Double, Double) and the target type is Location).\nIn case the target type is smaller than the source type, you can use the xmapPartial operation, which refines the carried type. As an example, here is how you can define a Segment[LocalDate]:\ncopysourceimport java.time.LocalDate\nimport endpoints4s.{Invalid, Valid}\n\nimplicit def localDateSegment(implicit\n    string: Segment[String]\n): Segment[LocalDate] =\n  string.xmapPartial { s =>\n    Try(LocalDate.parse(s)) match {\n      case Failure(_)    => Invalid(s\"Invalid date value '$s'\")\n      case Success(date) => Valid(date)\n    }\n  }(_.toString)\nThe first function passed to the xmapPartial operation returns a `Validated[LocalDate]` value. Returning an Invalid value means that there is no representation of the source type in the target type.","title":"Transforming and Refining URL Constituents"},{"location":"/algebras/endpoints.html#request-headers","text":"The type RequestHeaders[A] models request headers carrying some information of type A. For instance, a value of type RequestHeaders[Credentials] describes request headers containing credentials.\nPlease refer to the API documentation for details about constructors and operations for the type RequestHeaders.","title":"Request Headers"},{"location":"/algebras/endpoints.html#request-entity","text":"The type RequestEntity[A] models a request entity carrying some information of type A. For instance, a value of type RequestEntity[Command] describes a request entity containing a command.\nThe Endpoints algebra provides a few `RequestEntity` constructors and operations, which can be extended to support more content types. For instance, the JsonEntities algebra adds support for requests with JSON entities.","title":"Request Entity"},{"location":"/algebras/endpoints.html#response","text":"The Response[A] type models an HTTP response carrying some information of type A. For instance, a Response[User] value describes an HTTP response containing a user: client interpreters decode a User from the response entity, server interpreters encode a User as a response entity, and documentation interpreters render the serialization schema of a User.","title":"Response"},{"location":"/algebras/endpoints.html#constructing-responses","text":"A response is defined in terms of a status, headers and an entity. Here is an example of a simple OK response with no entity and no headers:\ncopysource// An HTTP response with status code 200 (Ok) and no entity\nval nothing: Response[Unit] = ok(emptyResponse)\nThere is a more general response constructor taking the status as parameter:\ncopysource// An HTTP response with status code 200 (Ok) and a text entity\nval aTextResponse: Response[String] = response(OK, textResponse)\nAdditional documentation about the response can be passed as an extra parameter:\ncopysourceok(\n  emptyResponse,\n  docs = Some(\"A response with an OK status code and no entity\")\n)","title":"Constructing Responses"},{"location":"/algebras/endpoints.html#response-headers","text":"The type ResponseHeaders[A] models response headers carrying some information of type A. For instance, a value of type ResponseHeaders[Origin] describes response headers containing an origin (e.g., an Access-Control-Allow-Origin header).\nRefer to the API documentation for details about constructors and operations for the type ResponseHeaders.","title":"Response Headers"},{"location":"/algebras/endpoints.html#response-entity","text":"The type ResponseEntity[A] models a response entity carrying some information of type A. For instance, a value of type ResponseEntity[Event] describes a response entity containing an event.\nThe Endpoints algebra provides a few `ResponseEntity` constructors and operations, which can be extended to support more content-types. For instance, the JsonEntities algebra adds support for responses with JSON entities.","title":"Response Entity"},{"location":"/algebras/endpoints.html#transforming-responses","text":"Responses have methods provided by the `ResponseSyntax` and the `InvariantFunctorSyntax` implicit classes, whose usage is illustrated in the remaining of this section.\nThe orNotFound operation is useful to handle resources that may not be found:\ncopysourceval getUser: Endpoint[Long, Option[User]] =\n  endpoint(\n    get(path / \"user\" / segment[Long](\"id\")),\n    ok(jsonResponse[User]).orNotFound()\n  )\nIn this example, servers can produce a Not Found (404) response by returning None, and an OK (200) response containing a user by returning a Some[User] value. Conversely, clients interpret a Not Found response as a None value, and an OK response (with a valid user entity) as a Some[User] value.\nMore generally, you can describe an alternative between two possible responses by using the orElse operation:\ncopysourceval maybeUserResponse: Response[Either[Unit, User]] =\n  response(NotImplemented, emptyResponse).orElse(ok(jsonResponse[User]))\nIn this example, servers can produce a Not Implemented (501) response by returning Left(()), and an OK (200) response containing a user by returning Right(user). Conversely, clients interpret a Not Implemented response as a Left(()) value, and an OK response (with a valid user entity) as a Right(user) value.\nYou can also transform the type produced by the alternative responses into a more convenient type to work with, by using the xmap operation. For instance, here is how to transform a Response[Either[Unit, User]] into a Response[Option[User]]:\ncopysourceval maybeUserResponse: Response[Option[User]] =\n  response(NotImplemented, emptyResponse)\n    .orElse(ok(jsonResponse[User]))\n    .xmap {\n      case Left(())    => None\n      case Right(user) => Some(user)\n    }(_.toRight(()))","title":"Transforming Responses"},{"location":"/algebras/endpoints.html#error-responses","text":"Server interpreters handle two kinds of errors:\nwhen the server is unable to decode an incoming request (because, for instance, a query parameter is missing, or the request entity has the wrong format). In this case it is a “client error” ; when the provided business logic throws an exception, or the server is unable to serialize the result into a proper HTTP response. In this case it is a “server error”.\nBy default, client errors are reported as an Invalid value, serialized into a Bad Request (400) response, as a JSON array containing string messages. You can change the provided serialization format by overriding the clientErrorsResponseEntity operation.\nSimilarly, by default server errors are reported as a Throwable value, serialized into an Internal Server Error (500) response, as a JSON array containing string messages. You can change the provided serialization format by overriding the serverErrorResponseEntity operation.","title":"Error Responses"},{"location":"/algebras/endpoints.html#middlewares","text":"Transformations of endpoint requests and responses can be defined in a reusable way as so-called middlewares. They are documented in a dedicated page.","title":"Middlewares"},{"location":"/algebras/endpoints.html#next-step","text":"See how you can describe endpoints with JSON entities.","title":"Next Step"},{"location":"/algebras/json-entities.html","text":"","title":"JSON Entities"},{"location":"/algebras/json-entities.html#json-entities","text":"The Endpoints algebra does not provide support for describing requests and responses containing JSON entities. The reason for this is that there are different algebra modules to use depending on your needs.\nThe following diagram summarizes which algebra to use in which case:\nThe first question to ask is “do I want to publish documentation of my endpoints?”. In order to document the JSON entities of your requests and responses you need a JSON schema for them, that’s why you have to use the JsonEntitiesFromSchemas algebra. See below for more details.\nIn case you don’t need to document the schema of your JSON entities, the second question to ask is “do I implement both a client and a server?”. If this is the case, then you need to be able to both encode and decode each JSON entity (an entity encoded by the server will be decoded by the client, and vice versa). To ensure that encoders and decoders are consistent together both have to be provided at the definition site of your endpoints, that’s why you should use the JsonEntitiesFromCodecs algebra. See below for more details.\nLast, if you answered “no” to both questions, it means that your endpoints will only be served by your server and you don’t need an (abstract) algebra to describe them: you can directly use the JsonEntitiesFromEncodersAndDecoders interpreter for your specific server. With this module, you will have to provide an encoder for JSON responses, and a decoder for JSON requests.\nNote Note that in a same service some endpoints might fall in a category, while some other endpoints might fall in a different category. For instance, if you want to publish an OpenAPI descriptor for your service, the endpoints to include in the documentation should be defined with the JsonEntitiesFromSchemas algebra, but the endpoint that serves the OpenAPI document itself will be defined with a JsonEntitiesFromEncodersAndDecoders module. See the OpenAPI interpreter documentation for an example.\nThe next section introduces general information about the JsonEntities hierarchy, and the remaining sections provide more details on how to use JsonEntitiesFromSchemas and JsonEntitiesFromCodecs.","title":"JSON Entities"},{"location":"/algebras/json-entities.html#the-jsonentities-algebras","text":"API documentation\nThe following diagram shows the relations between the three aforementioned algebras, JsonEntities, JsonEntitiesFromCodecs, and JsonEntitiesFromSchemas, and their relations with the other algebras:\nThe JsonEntities algebra adds to the Endpoints algebra the capability to describe JSON entities in requests and responses. The JsonEntitiesFromCodecs algebra refines the JsonEntities algebra by aligning the request and response entities to the same JsonCodec type. Finally, the JsonEntitiesFromSchemas algebra refines the JsonEntities algebra by aligning the request and response entities to the same JsonSchema type.\nThe JsonEntities module (and its specializations) enriches the Endpoints algebra with new constructors for request and response entities. For instance, here is how to define an endpoint taking in its request entity a JSON document for creating an user, and returning in its response entity the created user:\ncopysourceendpoint(\n  post(path / \"user\", jsonRequest[CreateUser]),\n  ok(jsonResponse[User])\n)\nThe jsonRequest[A] constructor defines a JSON request entity containing a value of type A, provided that there exists an implicit JsonRequest[A] instance. Similarly, the jsonResponse[A] constructor defines a JSON response entity containing a value of type A provided that there exists an implicit JsonResponse[A] instance.\nThe JsonRequest[A] and JsonResponse[A] types are kept abstract in the JsonEntities algebra. They mean that a value of type A can be serialized in a JSON request or a JSON response, respectively.\nThe various specializations of the JsonEntities algebra refine the JsonRequest[A] and JsonResponse[A] types.\nThe JsonEntitiesFromSchemas algebra fixes both types to the same JsonSchema[A] type, which comes from the JsonSchemas algebra (see below for more details).\nThe JsonEntitiesFromCodecs algebra fixes both types to a same JsonCodec[A] type, which can refer to Circe’s codec or Play JSON’s codecs according to the variant of JsonEntitiesFromCodecs that you use (see below for more details).\nDocumentation interpreters fix both types to be a JSON schema for A.\nLast, the JsonEntitiesFromEncodersAndDecoders server interpreters fix the JsonRequest[A] type to a JSON decoder for A, and the JsonResponse[A] type to a JSON encoder for A.","title":"The JsonEntities algebras"},{"location":"/algebras/json-entities.html#jsonentitiesfromschemas","text":"API documentation\nThis algebra merges the JsonEntities algebra and the JsonSchemas algebra and aligns both the JsonRequest[A] and JsonResponse[A] types to be JsonCodec[A], which is itself defined to the JsonSchema[A] type provided by the JsonSchemas algebra:\ncopysourcetype JsonCodec[A] = JsonSchema[A]\nThis means that you have to define such a JsonSchema[A] implicit value (as explained in the JsonSchemas documentation) for each type A that you want to carry as a JSON entity.\nThese schemas can then be interpreted as documentation (by applying the endpoints4s.openapi.JsonEntitiesFromSchemas interpreter), or codecs (by applying a corresponding interpreter for your client or server, e.g. endpoints4s.pekkohttp.server.JsonEntitiesFromSchemas to use an Pekko HTTP server).","title":"JsonEntitiesFromSchemas"},{"location":"/algebras/json-entities.html#jsonentitiesfromcodecs","text":"API documentation\nIn case you don’t need to document the JSON schemas of your request and response entities, the JsonEntitiesFromCodecs family of algebras is the preferred approach. These algebras fix both the JsonRequest and JsonResponse types to a same (abstract) JsonCodec type:\ncopysourcetype JsonCodec[A]\nBy using the same codec type for both types ensures that the encoding and decoding are consistent.\nGenerally, you want to use a JsonEntitiesFromCodecs algebra that fixes this JsonCodec type to a concrete type. An example is `endpoints4s.algebra.playjson.JsonEntitiesFromCodecs`, which aligns the JsonCodec type with Play’s Format type:\ncopysourcetype JsonCodec[A] = Format[A]\nThe Circe analogous is `endpoints4s.algebra.circe.JsonEntitiesFromCodecs`.\nThese algebras are provided by the following artifacts:\nTo interpret endpoints defined with such algebras, apply any interpreter named JsonEntitiesFromCodecs that matches your family of interpreters. For instance, if you use interpreters from the endpoints4s.xhr package (ie. the Scala.js web interpreters), you should use the endpoints4s.xhr.JsonEntitiesFromCodecs interpreter.","title":"JsonEntitiesFromCodecs"},{"location":"/algebras/json-schemas.html","text":"","title":"JSON Schemas"},{"location":"/algebras/json-schemas.html#json-schemas","text":"","title":"JSON Schemas"},{"location":"/algebras/json-schemas.html#jsonschemas","text":"This algebra provides vocabulary to define JSON schemas of data types.\nAPI documentation\nNote This module is dependency-free, it can be used independently of endpoints4s to define JSON schemas and interpret them as actual encoder, decoders or documentation.\nThe algebra introduces the concept of JsonSchema[A]: a JSON schema for a type A.","title":"JsonSchemas"},{"location":"/algebras/json-schemas.html#basic-types-and-record-types","text":"The trait provides some predefined JSON schemas (for String, Int, Boolean, Seq, etc.) and ways to combine them together to build more complex schemas.\nFor instance, given the following Rectangle data type:\ncopysourcecase class Rectangle(width: Double, height: Double)\nWe can represent instances of Rectangle in JSON with a JSON object having properties corresponding to the case class fields. A JSON schema for such objects would be defined as follows:\ncopysourceimplicit val rectangleSchema: JsonSchema[Rectangle] = (\n  field[Double](\"width\", Some(\"Rectangle width\")) zip\n    field[Double](\"height\")\n).xmap((Rectangle.apply _).tupled)(rect => (rect.width, rect.height))\nThe field constructor defines a JSON object schema with one field of the given type and name (and an optional text documentation). Two other constructors, optField and optFieldWithDefault, define optional fields in a JSON object.\nThe return type of rectangleSchema is declared to be JsonSchema[Rectangle], but we could have used a more specific type: Record[Rectangle]. This subtype of JsonSchema[Rectangle] provides additional operations such as zip or tagged (see the next section).\nIn the above example, we actually define two JSON object schemas (one for the width field, of type Record[Double], and one for the height field, of type Record[Double]), and then we combine them into a single JSON object schema by using the zip operation. Finally, we call the xmap operation to turn the Record[(Double, Double)] value returned by the zip operation into a Record[Rectangle].\nThe preciseField constructor defines a JSON object schema similar to optField. preciseField allows finer control by making a distinction between the property set with a null value and the absence of the property.","title":"Basic types and record types"},{"location":"/algebras/json-schemas.html#sum-types-sealed-traits-","text":"It is also possible to define schemas for sum types. Consider the following type definition, defining a Shape, which can be either a Circle or a Rectangle:\ncopysourcesealed trait Shape\ncase class Circle(radius: Double) extends Shape\ncase class Rectangle(width: Double, height: Double) extends Shape\nA possible JSON schema for this data type consists in using a JSON object with a discriminator field indicating whether the Shape is a Rectangle or a Circle. Such a schema can be defined as follows:\ncopysource// Given a `circleSchema: Record[Circle]` and a `rectangleSchema: Record[Rectangle]`\n(\n  circleSchema.tagged(\"Circle\") orElse\n    rectangleSchema.tagged(\"Rectangle\")\n).xmap[Shape] {\n  case Left(circle) => circle\n  case Right(rect)  => rect\n} {\n  case c: Circle    => Left(c)\n  case r: Rectangle => Right(r)\n}\n(We have omitted the definition of circleSchema for the sake of conciseness)\nFirst, all the alternative record schemas (in this example, circleSchema and rectangleSchema) must be tagged with a unique name. Then, the orElse operation combines the alternative schemas into a single schema that accepts one of them.\nThe result of the tagged operation is a Tagged[A] schema. This subtype of JsonSchema[A] models a schema that accepts one of several alternative schemas. It provides the orElse operation and adds a discriminator field to the schema.\nThe orElse operation turns the Tagged[Circle] and Tagged[Rectangle] values into a Tagged[Either[Circle, Rectangle]], which is then, in this example, transformed into a Tagged[Shape] by using xmap.\nBy default, the discriminator field used to distinguish between tagged alternatives is named type, but you can use another field name either by overriding the defaultDiscriminatorName method of the algebra, or by calling the withDiscriminator operation and specifying the field name to use.\nInstead of using orElse you can also make use of the orElseMerge operation. This is similar to orElse, but requires alternatives to share a parent. In the above example, this requirement is met since both Circle and Rectangle extend Shape. The orElseMerge operation turns the Tagged[Circle] and Tagged[Rectangle] values into a Tagged[Shape] without any mapping. Note, however, that orElseMerge uses ClassTag under the hood, and thus requires both alternatives to have distinct types after erasure. Our example is valid because Rectangle and Shape are distinct classes, but consider a type Resource[A]: then the types Resource[Rectangle] and Resource[Circle] have the same erased type (Resource[_]), making them indistinguishable by the orElseMerge operation. See also the documentation of isInstanceOf.","title":"Sum types (sealed traits)"},{"location":"/algebras/json-schemas.html#refining-schemas","text":"The examples above show how to use xmap to transform a JsonSchema[A] into a JsonSchema[B]. In case the transformation function from A to B can fail (for example, if it applies additional validation), you can use xmapPartial instead of xmap:\ncopysourceval evenNumberSchema: JsonSchema[Int] =\n  intJsonSchema.xmapPartial { n =>\n    if (n % 2 == 0) Valid(n)\n    else Invalid(s\"Invalid even integer '$n'\")\n  }(n => n)\nIn this example, we check that the decoded integer is even. If it is not, we return an error message.","title":"Refining schemas"},{"location":"/algebras/json-schemas.html#enumerations","text":"There are different ways to represent enumerations in Scala:\nscala.util.Enumeration Sealed trait with case objects Third-party libraries, e.g. Enumeratum\nFor example, an enumeration with three possible values can be defined as a sealed trait with three case objects:\ncopysourcesealed trait Status\ncase object Active extends Status\ncase object Inactive extends Status\ncase object Obsolete extends Status\nThe method stringEnumeration in the JsonSchemas algebra supports mapping the enum values to JSON strings. It has two parameters: the possible values, and a function to encode an enum value as a string.\ncopysourceimplicit lazy val statusSchema: JsonSchema[Status] =\n  stringEnumeration[Status](Seq(Active, Inactive, Obsolete))(_.toString)\nThe resulting JsonSchema[Status] allows defining JSON members with string values that are mapped to our case objects.\nIt will work similarly for other representations of enumerated values. Most of them provide values which can conveniently be passed into stringEnumeration. However, it is still possible to explicitly pass a certain subset of allowed values.","title":"Enumerations"},{"location":"/algebras/json-schemas.html#tuples","text":"JSON schemas for tuples from 2 to 22 elements are provided out of the box. For instance, if there are implicit JsonSchema instances for types A, B, and C, then you can summon a JsonSchema[(A, B, C)]. Tuples are modeled in JSON with arrays, as recommended in the JSON Schema documentation.\nHere is an example of JSON schema for a GeoJSON Point, where GPS coordinates are modeled with a pair (longitude, latitude):\ncopysourcetype Coordinates = (Double, Double) // (Longitude, Latitude)\ncase class Point(coordinates: Coordinates)\n\nimplicit val pointSchema: JsonSchema[Point] = (\n  field(\"type\")(literal(\"Point\")) zip\n    field[Coordinates](\"coordinates\")\n).xmap(Point(_))(_.coordinates)","title":"Tuples"},{"location":"/algebras/json-schemas.html#recursive-types","text":"You can reference a currently being defined schema without causing a StackOverflow error by wrapping it in the lazyRecord or lazyTagged constructor:\ncopysourcecase class Recursive(next: Option[Recursive])\n\nval recursiveSchema: Record[Recursive] = lazyRecord(\"Rec\")(\n  optField(\"next\")(recursiveSchema)\n).xmap(Recursive(_))(_.next)","title":"Recursive types"},{"location":"/algebras/json-schemas.html#alternatives-between-schemas","text":"You can define a schema as an alternative between other schemas with the operation orFallbackTo:\ncopysourceval intOrBoolean: JsonSchema[Either[Int, Boolean]] =\n  intJsonSchema.orFallbackTo(booleanJsonSchema)\nWarning Because decoders derived from schemas defined with the operation orFallbackTo literally “fallback” from one alternative to another, it makes it impossible to report good decoding failure messages. You should generally prefer using orElse on “tagged” schemas.","title":"Alternatives between schemas"},{"location":"/algebras/json-schemas.html#schemas-documentation","text":"Schema descriptions can include documentation information which is used by documentation interpreters such as the OpenAPI interpreter. We have already seen in the first section that object fields could be documented with a description. This section shows other features related to schemas documentation.\nYou can include a description and an example of value for a schema (see the Swagger “Adding Examples” documentation), with the operations withDescription and withExample, respectively:\ncopysourceimplicit val rectangleSchema: JsonSchema[Rectangle] = (\n  field[Double](\"width\", Some(\"Rectangle width\")) zip\n    field[Double](\"height\")\n).xmap((Rectangle.apply _).tupled)(rect => (rect.width, rect.height))\n  .withExample(Rectangle(10, 20))\n  .withDescription(\"A rectangle shape\")\nApplying the OpenAPI interpreter to this schema definition produces the following JSON document:\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"width\": {\n      \"type\": \"number\",\n      \"format\":\"double\",\n      \"description\": \"Rectangle width\"\n    },\n    \"height\":{\n      \"type\": \"number\",\n      \"format\": \"double\"\n    }\n  },\n  \"required\": [\"width\",\"height\"],\n  \"description\": \"A rectangle shape\",\n  \"example\": { \"width\": 10, \"height\": 20 }\n}\nThe encoding of sealed traits in OpenAPI can be configured by overriding the coproductEncoding method in the OpenAPI interpreter. By default, the OpenAPI interpreter will encode variants of sealed traits in the same way that they would be encoded if they were standalone records. However, it is sometimes useful to include in each variants’ schema a reference to the base type schema. The API documentation has more details.\nYou can give names to schemas. These names are used by the OpenAPI interpreter to group the schema definitions at one place, and then reference each schema by its name (see the Swagger “Components Section” documentation).\nUse the named method to give a name to a Record, a Tagged, or an Enum schema.\nWarning Note that schema names must be valid URLs.","title":"Schemas documentation"},{"location":"/algebras/json-schemas.html#generic-derivation-of-json-schemas-based-on-shapeless-","text":"The module presented in this section uses Shapeless to generically derive JSON schemas for algebraic data type definitions (sealed traits and case classes).\nAPI documentation","title":"Generic derivation of JSON schemas (based on Shapeless)"},{"location":"/algebras/json-schemas.html#json-schemas-derivation","text":"With this module, defining the JSON schema of the Shape data type is reduced to the following:\ncopysourceimplicit val shapeSchema: JsonSchema[Shape] = genericJsonSchema\nThe genericJsonSchema operation builds a JSON schema for the given type. The rules for deriving the schema are the following:\nthe schema of a case class is a JSON object, the schema of a sealed trait is the alternative of its leaf case class schemas, discriminated by the case class names, each case class field has a corresponding required JSON object property of the same name and type (for instance, the generic schema for the Rectangle type has a width required property of type integer), each case class field of type Option[A] for some type A has a corresponding optional JSON object property of the same name and type, each case class field with a default value has a corresponding optional JSON object property of the same name and type (decoders produce the default value when the property is missing), descriptions can be set for case class fields, case classes, or sealed traits by annotating these things with the @docs annotation, for sealed traits, the discriminator field name can be defined by the @discriminator annotation, otherwise the defaultDiscriminatorName value is used, the schema is named by the @name annotation, if present, or by invoking the classTagToSchemaName operation with the ClassTag of the type for which the schema is derived. If you wish to avoid naming the schema, use the @unnamed annotation (unnamed schemas get inlined in their OpenAPI documentation). the schema title is set with the @title annotation, if present.\nHere is an example that illustrates how to configure the generic schema derivation process:\ncopysource@discriminator(\"kind\")\n@title(\"Geometric shape\")\n@name(\"ShapeSchema\")\nsealed trait Shape\n\n@name(\"CircleSchema\")\ncase class Circle(radius: Double) extends Shape\n\n@name(\"RectangleSchema\")\n@docs(\"A quadrilateral with four right angles\")\ncase class Rectangle(\n    @docs(\"Rectangle width\") width: Double,\n    height: Double\n)\nIn case you need to transform further a generically derived schema, you might want to use the genericRecord or genericTagged operations instead of genericJsonSchema. These operations have a more specific return type than genericJsonSchema: genericRecord returns a Record, and genericTagged returns a Tagged.","title":"JSON schemas derivation"},{"location":"/algebras/json-schemas.html#json-schemas-transformation","text":"The module also takes advantage shapeless to provide a more convenient as operation for transforming JSON schema definitions, instead of xmap:\ncopysourceimplicit val rectangleSchema: JsonSchema[Rectangle] = (\n  field[Double](\"width\") zip\n    field[Double](\"height\")\n).as[Rectangle]","title":"JSON schemas transformation"},{"location":"/algebras/json-schemas.html#mixing-hand-written-and-derived-schemas","text":"The generic derivation mechanism for sealed traits derives a schema for each case class extending the trait. Sometimes, you want to use a custom schema for one of the case classes. You can achieve this by providing an implicit GenericRecord instance for your case class:\ncopysourcesealed trait Shape\ncase class Circle(radius: Double) extends Shape\ncase class Rectangle(width: Double, height: Double) extends Shape\n\nimplicit val shapeSchema: JsonSchema[Shape] = {\n  // For some reason, our JSON representation uses a `diameter`\n  // rather than a `radius`\n  val circleSchema: Record[Circle] =\n    field[Double](\"diameter\")\n      .xmap(diameter => Circle(diameter / 2))(circle => circle.radius * 2)\n  implicit val circleGenericRecord: GenericJsonSchema.GenericRecord[Circle] =\n    new GenericJsonSchema.GenericRecord(circleSchema)\n  // The generic schema for `Shape` will synthesize the schema for `Rectangle`,\n  // but it will use the implicitly provided `GenericRecord[Circle]` for `Circle.\n  genericJsonSchema[Shape]\n}","title":"Mixing hand-written and derived schemas"},{"location":"/algebras/json-schemas.html#generic-derivation-of-json-schemas-based-on-macros-","text":"An alternative to the module presented in the preceding section is provided as a third-party module: endpoints-json-schemas-macros.\nPlease see the README of that project for more information on how to use it and its differences with the module provided by endpoints4s.","title":"Generic derivation of JSON schemas (based on macros)"},{"location":"/algebras/chunked-entities.html","text":"","title":"Chunked Entities"},{"location":"/algebras/chunked-entities.html#chunked-entities","text":"","title":"Chunked Entities"},{"location":"/algebras/chunked-entities.html#chunkedentities","text":"This algebra provides vocabulary to describe endpoints whose requests or responses are streamed using the “chunked transfer-encoding” supported by HTTP1.1.\nAPI documentation\nThe ChunkedEntities module enriches the Endpoints algebra with operations for defining request and responses entities carrying stream of values.\nFor instance, you can define an endpoint streaming a binary file as follows:\ncopysourceval logo: Endpoint[Unit, Chunks[Array[Byte]]] =\n  endpoint(get(path / \"logo.png\"), ok(bytesChunksResponse))\nThe return type, Endpoint[Unit, Chunks[Array[Byte]]], represents an endpoint whose request takes no parameter (Unit) and whose response produces a stream of Array[Byte] chunks.\nResponses are streamed using the chunked transfer-encoding, which is supported by most HTTP 1.1 clients and servers.","title":"ChunkedEntities"},{"location":"/algebras/chunked-entities.html#chunkedjsonentities","text":"API documentation\nClients and servers have to agree on the serialization format used by response chunks and WebSocket messages. The ChunkedJsonEntities module provides a jsonChunksRequest constructor and a jsonChunksResponse constructor for defining request entities and response entities carrying streams of values that are serialized into JSON. In addition, entity constructors must also be provided with an implementation of chunk framing, which is defined by the Framing module. This is required to compensate for the fact that the chunks of “chunked transfer-encoding” can be re-framed during transport, and thus cannot solely be relied on as a method of framing. The library provides the constructor for newLineDelimiterFraming, which delimits each frame by a new-line character:\ncopysourcetrait JsonStreamingExample\n    extends endpoints4s.algebra.Endpoints\n    with endpoints4s.algebra.ChunkedJsonEntities\n    with endpoints4s.algebra.JsonEntitiesFromSchemas {\n\n  val ticks =\n    endpoint(get(path / \"ticks\"), ok(jsonChunksResponse[Unit](newLineDelimiterFraming)))\n\n}\nThis example uses the JsonEntitiesFromSchemas algebra to derive the JSON serialization format from a JSON schema, which can also be reused by the OpenAPI interpreter.\nEventually, mix a JsonEntitiesFromSchemas interpreter of your choice to turn the JSON schemas into proper JSON codecs. For instance, for Pekko-Http:\ncopysourceimport org.apache.pekko.stream.scaladsl.Source\nimport endpoints4s.pekkohttp.server\n\nobject JsonStreamingExampleServer\n    extends JsonStreamingExample\n    with server.Endpoints\n    with server.ChunkedJsonEntities\n    with server.JsonEntitiesFromSchemas {\n\n  val routes =\n    ticks.implementedBy(_ => Source.tick(0.seconds, 1.second, ()))\n\n}","title":"ChunkedJsonEntities"},{"location":"/algebras/chunked-entities.html#custom-serialization-format","text":"Support for other serialization formats can be added by defining an operation returning a Chunks[A] value. For instance, the Protocol Buffers format would be supported as follows (using protoless):\nimport endpoints4s.algebra\nimport io.protoless.messages.{Decoder, Encoder}\n\ntrait ProtobufChunkedEntities extends algebra.ChunkedEntities {\n  /** Streams containing values of type `A`, serialized with the given protobuf codec */\n  def protobufChunksRequest[A : Encoder : Decoder]: RequestEntity[Chunks[A]]\n}\nAnd then, the protobufChunksRequest operation would have to be implemented on each interpreter.","title":"Custom Serialization Format"},{"location":"/algebras/middlewares.html","text":"","title":"Middlewares"},{"location":"/algebras/middlewares.html#middlewares","text":"The Endpoints algebra provides operations for transforming endpoint descriptions to enrich their request, their response, or their documentation. These transformation operations are documented here.\nAPI documentation","title":"Middlewares"},{"location":"/algebras/middlewares.html#overview","text":"Middlewares allow you to define reusable transformations of endpoint requests, responses, or documentation. These transformations are reusable because they can be applied to arbitrary endpoint descriptions. Let’s look at an example.\nConsider a service that requires all the requests to provide a custom header named X-API-Key. The endpoints of such a service could be defined as follows:\ncopysourceval xApiKeyHeader = requestHeader(\"X-API-Key\", Some(\"API Key\"))\n\nval foo = endpoint(\n  get(path / \"foo\", headers = xApiKeyHeader),\n  ok(textResponse)\n)\n\nval bar = endpoint(\n  get(path / \"bar\", headers = xApiKeyHeader),\n  ok(textResponse)\n)\nWe first define the description of the request header in a value xApiKeyHeader, which we add to every endpoint definition. It is nice to be able to just reuse the xApiKeyHeader value everywhere, but if at some point we wanted to change the way the service supports authentication — e.g., by using a query parameter instead of a header, we would have to update all the request definitions accordingly.\nAlternatively, enriching a request definition with the fact that it also carries an API key could be defined as a reusable transformation:\ncopysourcedef withApiKey[A](request: Request[A]): Request[(A, String)] =\n  request.addHeaders(requestHeader(\"X-API-Key\", Some(\"API Key\")))\n\nval foo = endpoint(\n  withApiKey(get(path / \"foo\")),\n  ok(textResponse)\n)\n\nval bar = endpoint(\n  withApiKey(get(path / \"bar\")),\n  ok(textResponse)\n)\nThe method withApiKey takes a request description and enriches it with the desired header by using the operation addHeaders. We apply it to the subsequent request definitions. Now, if we decided to use a query parameter to carry the API key instead of a request header, we would just change the body of the method withApiKey:\ncopysourcedef withApiKey[A](request: Request[A]): Request[(A, String)] =\n  request.addQueryString(qs[String](\"api_key\"))\nThe following sections describe all the transformation operations that can be applied to requests, responses, and documentation.\nNote As shown, withApiKey is a method that takes a Request[A] and returns a Request[(A, String)] (the API key is modeled as a String). A drawback of this signature is that if we apply it to a Request[Unit] (ie, a request that carries no information), we get back a Request[(Unit, String)], although a Request[String] would have been preferable (a tuple with an element of type Unit is useless). It is possible to fix this issue by using an implicit Tupler. See the corresponding documentation.","title":"Overview"},{"location":"/algebras/middlewares.html#transforming-requests","text":"A request description can be enriched by adding headers or query parameters with the operations addHeaders and addQueryString, respectively. Both operations were showcased in the previous section.\nAs their names suggest, these operations can only add new headers or query parameters to a request, they can’t replace the existing constituents of a request.","title":"Transforming Requests"},{"location":"/algebras/middlewares.html#transforming-responses","text":"Responses can be enriched by using the orElse operation (already documented here), or by using the addHeaders operation, which is similar to the one defined on requests.\nLike with requests, these operations can only enrich responses, they can’t replace their constituents.","title":"Transforming Responses"},{"location":"/algebras/middlewares.html#transforming-endpoints","text":"Complex transformations can be applied to a whole endpoint description by using the operations mapRequest, mapResponse, or mapDocs, as shown in the following example, which transforms an arbitrary endpoint description into an endpoint that is protected by HTTP basic authentication.\ncopysourcedef withAuthentication[A, B](\n    endpoint: Endpoint[A, B]\n): Endpoint[(A, String), Either[String, B]] =\n  endpoint\n    .mapRequest { (endpointRequest: Request[A]) =>\n      endpointRequest.addHeaders(requestHeader(\"Authorization\"))\n    }\n    .mapResponse { (endpointResponse: Response[B]) =>\n      val unauthorizedResponse: Response[String] =\n        response(\n          Unauthorized,\n          emptyResponse,\n          headers = responseHeader(\"WWW-Authenticate\")\n        )\n      unauthorizedResponse.orElse(endpointResponse)\n    }\nThe method withAuthentication takes any endpoint description, and enriches its request description to include the Authorization header, and its response description to include the Unauthorized response containing the WWW-Authenticate header.\nHere is an example of usage of the method withAuthentication:\ncopysourceval unauthenticatedEndpoint: Endpoint[Int, String] =\n  endpoint(\n    get(path / \"foo\" /? qs[Int](\"n\")),\n    ok(textResponse)\n  )\nval authenticatedEndpoint: Endpoint[(Int, String), Either[String, String]] =\n  withAuthentication(unauthenticatedEndpoint)\nThe endpoint unauthenticatedEndpoint has type Endpoint[Int, String]. Its request carries a value of type Int (passed as a query parameter), and its response carries a value of type String (provided by the response entity).\nWhen we apply the method withAuthentication to the endpoint description, we get back an Endpoint[(Int, String), Either[String, String]]. It carries a pair of type (Int, String) in its request (the initial query parameter of type Int, and the credentials content of type String), and now its response has type Either[String, String] (it will be a Left with the content of the WWW-Authenticate header in case of incorrect credentials, or a Right if authentication succeeds).\nThe method mapRequest on the type Endpoint[A, B] takes as parameter a transformation function. This function turns the initial Request[A] into a Request[C] (for any type C). So, the resulting endpoint has type Endpoint[C, B]:\ncopysourcedef mapRequest[C](func: Request[A] => Request[C]): Endpoint[C, B]\nThe method mapResponse works similarly, but it takes as parameter a transformation function that turns the initial Response[B] into a Response[C] (for any type C).\nLast, there is also a method mapDocs, which takes as parameter a function that transforms the initial EndpointDocs into another EndpointDocs value.","title":"Transforming Endpoints"},{"location":"/algebras/assets.html","text":"","title":"Assets"},{"location":"/algebras/assets.html#assets","text":"This algebra provides vocabulary to define endpoints serving static assets.\nAPI documentation\nThe module enriches the Endpoints algebra with new constructors for endpoints and path segments. It also introduces the concepts of AssetRequest, AssetResponse and AssetPath. The typical usage looks like the following:\ncopysourceval assets: Endpoint[AssetRequest, AssetResponse] =\n  assetsEndpoint(path / \"assets\" / assetSegments())\nThe assetsSegments method defines a path containing (possibly) multiple segments.\nThe concrete instantiation of the AssetRequest and AssetResponse types is left to interpreters. Typically, AssetResponse is mapped to binary data. Interpreters also have to provide a constructor for AssetRequest, so that the endpoint can be called. Typically, such constructors take the path of the asset as a String parameter.\nServer interpreters are encouraged to leverage caching HTTP headers such as ETag or Cache-Control, and gzip content encoding. Incidentally, the algebra provides an abstract digest: Map[String, String] member to be overridden by users with digests uniquely identifying the assets:\ncopysourceval digests = Map(\"main.css\" -> \"2018-10-09T14:32:12Z\")\nThe content of the digests can be included to the asset segments so that servers know that the requested version of the asset matches the one it uses, enabling servers to indefinitely cache the asset.","title":"Assets"},{"location":"/algebras/mux-endpoints.html","text":"","title":"Multiplexed Endpoints"},{"location":"/algebras/mux-endpoints.html#multiplexed-endpoints","text":"This algebra provides vocabulary to define endpoints multiplexing several requests and responses.\nAPI documentation\nIn general, each possible resource or action supported by a service is exposed through a specific endpoint, taking a specific request type and a specific response type.\nHowever, in some cases it is useful to use a same endpoint to manage several resources or actions. We call them multiplexed endpoints.\nThe algebra enriches the Endpoints algebra with the concept of MuxEndpoint[Req, Resp, Transport], defining a multiplexed endpoint with a request containing a type Req, a response of type Resp, and serializing data to and from the Transport type.\nFor instance, the type MuxEndpoint[Command, Event, Json] defines and endpoint whose requests contain Command values, whose responses contain Event values, and which serialize commands and events to Json.\nSince the type of a response can vary according to the type of specific request, multiplexed endpoints require that request types extend the MuxRequest type:\ncopysourceval users: MuxEndpoint[Command, Event, Json] =\n  muxEndpoint[Command, Event, Json](\n    post(path / \"users\", jsonRequest[Json]),\n    ok(jsonResponse[Json])\n  )\n\n// Types of commands\nsealed trait Command extends MuxRequest\nfinal case class CreateUser(name: String) extends Command {\n  type Response = UserCreated\n}\nfinal case class DeleteUser(id: Long) extends Command {\n  type Response = UserDeleted\n}\n\n// Types of responses\ntrait Event\ncase class UserCreated(id: Long) extends Event\ncase class UserDeleted(id: Long) extends Event\nNote that the Command request type extends MuxRequest and that each concrete Command refines its Response type member to refer to a concrete Event type.\nTypically, client interpreters fix the MuxEndpoint[Req, Resp, Transport] type to be a function from Req to Future[Req#Response], so that calling users(CreateUser(\"Alice\")) (statically) returns a Future[CreatedUser], and calling users(DeleteUser(42)) returns a Future[DeletedUser].","title":"Multiplexed Endpoints"},{"location":"/interpreters/pekko-http.html","text":"","title":"Pekko HTTP"},{"location":"/interpreters/pekko-http.html#pekko-http","text":"Client and server backed by Pekko HTTP.\nWarning As explained in the section Mixed versioning is not allowed in the Pekko documentation, you have to make sure that all the Pekko modules of your application have the same version. For this reason, the interpreters pekko-http-server and pekko-http-client have marked their dependency to Pekko as “provided”. As a consequence, to use these interpreters you will have to explicitly add a dependency on pekko-stream: \"org.apache.pekko\" %% \"pekko-stream\" % \"<pekko-version>\"\n Where <pekko-version> is binary compatible and higher or equal to 1.0.1.","title":"Pekko HTTP"},{"location":"/interpreters/pekko-http.html#client","text":"API documentation","title":"Client"},{"location":"/interpreters/pekko-http.html#endpoints4s-pekkohttp-client-endpoints","text":"The Endpoints interpreter fixes the Endpoint[A, B] type to a function from A to Future[B]:\ncopysourcecase class Endpoint[A, B](\n    request: Request[A],\n    response: Response[B]\n) extends (A => Future[B])\nThis means that, given the following endpoint definition:\ncopysourceval someResource: Endpoint[Int, String] =\n  endpoint(get(path / \"some-resource\" / segment[Int]()), ok(textResponse))\nIt can be invoked as follows:\ncopysourceval eventuallyString: Future[String] = someResource(42)","title":"endpoints4s.pekkohttp.client.Endpoints"},{"location":"/interpreters/pekko-http.html#endpoints4s-pekkohttp-client-chunkedentities","text":"The ChunkedEntities interpreter fixes the Chunks[A] type to pekko.stream.scaladsl.Source[A, _]:\ncopysourcetype Chunks[A] = org.apache.pekko.stream.scaladsl.Source[A, _]\nThis means that, given the following endpoint definition:\ncopysourceval logo: Endpoint[Unit, Chunks[Array[Byte]]] =\n  endpoint(get(path / \"logo.png\"), ok(bytesChunksResponse))\nIt can be invoked as follows:\ncopysourceimport org.apache.pekko.stream.scaladsl.Source\n\nval bytesSource: Source[Array[Byte], _] =\n  Source.futureSource(logo(()))\n\nbytesSource.runForeach { bytes => println(s\"Received ${bytes.length} bytes\") }","title":"endpoints4s.pekkohttp.client.ChunkedEntities"},{"location":"/interpreters/pekko-http.html#server","text":"API documentation","title":"Server"},{"location":"/interpreters/pekko-http.html#endpoints4s-pekkohttp-server-endpoints","text":"The Endpoints interpreter fixes the Endpoint[A, B] type to something that, given an implementation function A => B, returns an org.apache.pekko.http.scaladsl.server.Route that can be integrated to your Pekko HTTP application.\nFor instance, given the following endpoint definition:\ncopysourceval someResource: Endpoint[Int, String] =\n  endpoint(get(path / \"some-resource\" / segment[Int]()), ok(textResponse))\nIt can be implemented as follows:\ncopysourceval route: Route =\n  someResource.implementedBy(x => s\"Received $x\")\nAlternatively, there is also a method implementedByAsync that takes an implementing function returning a Future[B].","title":"endpoints4s.pekkohttp.server.Endpoints"},{"location":"/interpreters/pekko-http.html#endpoints4s-pekkohttp-server-chunkedentities","text":"The ChunkedEntities interpreter fixes the Chunks[A] type to pekko.stream.scaladsl.Source[A, _].\nFor instance, given the following chunked endpoint definition:\ncopysourceval logo: Endpoint[Unit, Chunks[Array[Byte]]] =\n  endpoint(get(path / \"logo.png\"), ok(bytesChunksResponse))\nIt can be implemented as follows:\ncopysourceimport java.nio.file.Paths\nimport org.apache.pekko.stream.scaladsl.FileIO\n\nval logoRoute: Route =\n  logo.implementedBy { _ =>\n    FileIO.fromPath(Paths.get(\"/foo/bar/logo.png\")).map(_.toArray)\n  }","title":"endpoints4s.pekkohttp.server.ChunkedEntities"},{"location":"/interpreters/pekko-http.html#error-handling","text":"When the server processes requests, three kinds of errors can happen: the incoming request doesn’t match any endpoint, the request does match an endpoint but is invalid (e.g. one parameter has a wrong type), or an exception is thrown.","title":"Error handling"},{"location":"/interpreters/pekko-http.html#the-incoming-request-doesn-t-match-any-endpoint","text":"In that case, the routes constructed by endpoints4s can’t do anything. You have to deal with such errors in the usual Pekko HTTP way: by using an implicit org.apache.pekko.http.scaladsl.server.RejectionHandler having a handleNotFound clause.","title":"The incoming request doesn’t match any endpoint"},{"location":"/interpreters/pekko-http.html#the-incoming-request-is-invalid","text":"In that case, endpoints4s returns a “Bad Request” (400) response reporting all the errors in a JSON array. You can change this behavior by overriding the handleClientErrors method.","title":"The incoming request is invalid"},{"location":"/interpreters/pekko-http.html#an-exception-is-thrown","text":"If an exception is thrown during request decoding, or when running the business logic, or when encoding the response, endpoints4s returns an “Internal Server Error” (500) response reporting the error in a JSON array. You can change this behavior by overriding the handleServerError method.","title":"An exception is thrown"},{"location":"/interpreters/http4s.html","text":"","title":"http4s"},{"location":"/interpreters/http4s.html#http4s","text":"Client and server backed by http4s.","title":"http4s"},{"location":"/interpreters/http4s.html#client","text":"API documentation","title":"Client"},{"location":"/interpreters/http4s.html#endpoints4s-http4s-client-endpoints","text":"The Endpoints interpreter provides a trait Endpoint[A, B] with methods send and sendAndConsume, to invoke an endpoint.\nThis means that, given the following endpoint definition:\ncopysourceval someResource: Endpoint[Int, String] =\n  endpoint(get(path / \"some-resource\" / segment[Int]()), ok(textResponse))\nIt can be invoked as follows using IO:\ncopysourceval eventuallyString: IO[String] = someResource.sendAndConsume(42)","title":"endpoints4s.http4s.client.Endpoints"},{"location":"/interpreters/http4s.html#chunkedentities","text":"The ChunkedEntities interpreter fixes the Chunks[A] type to fs2.Stream[Effect, A]:\ncopysourcetype Chunks[A] = fs2.Stream[Effect, A]\nThis means that, given the following endpoint definition:\ncopysourceval logo: Endpoint[Unit, Chunks[Array[Byte]]] =\n  endpoint(get(path / \"logo.png\"), ok(bytesChunksResponse))\nIt can be invoked as follows:\ncopysourceval bytesSource: Resource[Effect, fs2.Stream[Effect, Array[Byte]]] =\n  logo.send(())\n\nbytesSource.use(stream =>\n  stream.evalMap { bytes => IO(println(s\"Received ${bytes.length} bytes\")) }.compile.drain\n)","title":"ChunkedEntities"},{"location":"/interpreters/http4s.html#server","text":"API documentation","title":"Server"},{"location":"/interpreters/http4s.html#endpoints4s-http4s-server-endpoints","text":"The Endpoints interpreter provides a routesFromEndpoints operation that turns a sequence of endpoints with their implementation into an org.http4s.HttpRoutes[F] value that can be integrated to your http4s application.\nFor instance, given the following endpoint definition:\ncopysourceval someResource: Endpoint[Int, String] =\n  endpoint(get(path / \"some-resource\" / segment[Int]()), ok(textResponse))\nIt can be implemented as follows:\ncopysourceval routes: HttpRoutes[IO] = HttpRoutes.of(\n  routesFromEndpoints(\n    someResource.implementedBy(x => s\"Received $x\")\n  )\n)\nThe result is a regular value of type org.http4s.HttpRoute[IO] that can be integrated in your application like any other http4s service.","title":"endpoints4s.http4s.server.Endpoints"},{"location":"/interpreters/http4s.html#error-handling","text":"When the server processes requests, three kinds of errors can happen: the incoming request doesn’t match any endpoint, the request does match an endpoint but is invalid (e.g. one parameter has a wrong type), or an exception is thrown.","title":"Error handling"},{"location":"/interpreters/http4s.html#the-incoming-request-doesn-t-match-any-endpoint","text":"In that case, the router constructed by endpoints4s can’t do anything. You have to deal with such errors in the usual http4s way (usually, by adding a .orNotFound call to your application services).","title":"The incoming request doesn’t match any endpoint"},{"location":"/interpreters/http4s.html#the-incoming-request-is-invalid","text":"In that case, endpoints4s returns a “Bad Request” (400) response reporting all the errors in a JSON array. You can change this behavior by overriding the handleClientErrors method.","title":"The incoming request is invalid"},{"location":"/interpreters/http4s.html#an-exception-is-thrown","text":"If an exception is thrown during request decoding, or when running the business logic, or when encoding the response, endpoints4s returns an “Internal Server Error” (500) response reporting the error in a JSON array. You can change this behavior by overriding the handleServerError method.","title":"An exception is thrown"},{"location":"/interpreters/scalajs-web-fetch.html","text":"","title":"Scala.js web client (Fetch)"},{"location":"/interpreters/scalajs-web-fetch.html#scala-js-web-client-fetch-","text":"Web client using Fetch.\nAPI documentation\nThe Endpoints interpreter fixes the type Endpoint[A, B] to a function from A to Result[B], where Result is abstract and is intended to be defined by more specialized interpreters.\nAn example of such an interpreter is endpoints4s.fetch.client.future.Endpoints, which fixes the Result[A] type to scala.concurrent.Future[A].\nThis means that, given the following endpoint definition:\ncopysourceval someResource: Endpoint[Int, String] =\n  endpoint(get(path / \"some-resource\" / segment[Int]()), ok(textResponse))\nIt can be invoked as follows:\ncopysourceval eventuallyString: Future[String] = someResource(42).future","title":"Scala.js web client (Fetch)"},{"location":"/interpreters/sttp.html","text":"","title":"sttp"},{"location":"/interpreters/sttp.html#sttp","text":"Client backed by sttp.\nAPI documentation\nThe Endpoints interpreter is parameterized by an sttp backend of type SttpBackend[R, Nothing], for some type constructor R[_].\nThe Endpoint[A, B] type is fixed as follows:\ncopysourcecase class Endpoint[A, B](request: Request[A], response: Response[B])\n    extends (A => R[B])\nThis means that, given the following endpoint definition:\ncopysourceval someResource: Endpoint[Int, String] =\nendpoint(get(path / \"some-resource\" / segment[Int]()), ok(textResponse))\nIt can be invoked as follows with the HttpURLConnectionBackend, for instance:\ncopysourceval string: String = someResource(42)","title":"sttp"},{"location":"/interpreters/openapi.html","text":"","title":"OpenAPI"},{"location":"/interpreters/openapi.html#openapi","text":"API documentation\nThis family of interpreters produces static documentation for endpoint definitions, in the form of an OpenAPI document.","title":"OpenAPI"},{"location":"/interpreters/openapi.html#endpoints","text":"The Endpoints interpreter provides an openApi method that takes as parameter a sequence of endpoints for which to generate an OpenAPI document.\nGiven the following endpoint definition:\ncopysourceimport endpoints4s.algebra\n\ntrait DocumentedEndpoints extends algebra.Endpoints {\n\n  val someDocumentedResource: Endpoint[Int, String] =\n    endpoint(\n      get(path / \"some-resource\" / segment[Int](\"id\")),\n      ok(textResponse, docs = Some(\"The content of the resource\"))\n    )\n\n}\nIt can be documented as follows:\ncopysourceimport endpoints4s.openapi\nimport endpoints4s.openapi.model.{Info, OpenApi}\n\nobject EndpointsDocs extends DocumentedEndpoints with openapi.Endpoints {\n\n  val api: OpenApi =\n    openApi(Info(title = \"API to get some resource\", version = \"1.0\"))(\n      someDocumentedResource\n    )\n\n}\nThe value returned by the openApi method has type endpoints4s.openapi.models.OpenApi, which is an abstract model for OpenAPI documents. You can encode it into JSON by using the OpenApi.stringEncoder encoder.\ncopysourceval apiJson: String = OpenApi.stringEncoder.encode(api)\nIn case the endpoint that serves the documentation is itself defined using endpoints, you can use the JsonEntitiesFromEncoderAndDecoder interpreter to define an endpoint returning the OpenApi document as a JSON entity. Here is an example using Pekko HTTP:\ncopysourceimport endpoints4s.openapi.model.OpenApi\nimport endpoints4s.pekkohttp.server\n\nobject DocumentationServer\n    extends server.Endpoints\n    with server.JsonEntitiesFromEncodersAndDecoders {\n\n  val routes =\n    endpoint(get(path / \"documentation.json\"), ok(jsonResponse[OpenApi]))\n      .implementedBy(_ => CounterDocumentation.api)\n\n}\nFinally, the apiJson value contains the following JSON document:\n{\n  \"openapi\" : \"3.0.0\",\n  \"info\" : {\n    \"title\" : \"API to get some resource\",\n    \"version\" : \"1.0\"\n  },\n  \"paths\" : {\n    \"/some-resource/{id}\" : {\n      \"get\" : {\n        \"parameters\" : [\n          {\n            \"name\" : \"id\",\n            \"in\" : \"path\",\n            \"schema\" : {\n              \"type\" : \"integer\"\n            },\n            \"required\" : true\n          }\n        ],\n        \"responses\" : {\n          \"200\" : {\n            \"description\" : \"The content of the resource\",\n            \"content\" : {\n              \"text/plain\" : {\n                \"schema\" : {\n                  \"type\" : \"string\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}","title":"Endpoints"},{"location":"/interpreters/openapi.html#json-entities","text":"To properly document the underlying JSON schema of your JSON entities, you have to define these schemas by using the JsonEntitiesFromSchemas algebra (and its corresponding interpreter).","title":"JSON entities"},{"location":"/interpreters/circe.html","text":"","title":"Circe"},{"location":"/interpreters/circe.html#circe","text":"Builds Circe codecs out of JSON schema definitions.\nAPI documentation\nThe JsonSchemas interpreter fixes the JsonSchema[A] to a type that provides both an io.circe.Encoder[A] and an io.circe.Decoder[A].\nGiven the following type definition:\ncopysourcesealed trait Shape\ncase class Circle(radius: Double) extends Shape\ncase class Rectangle(width: Double, height: Double) extends Shape\nAssuming that there is an implicit JsonSchema[Shape] definition, we can encode a Shape into JSON and decode it using the usual circe operations:\ncopysourceimport JsonSchema._\nval shape: Shape = Circle(42)\nval shapeJson: Json = shape.asJson\nval maybeShape: Either[circe.Error, Shape] = shapeJson.as[Shape]","title":"Circe"},{"location":"/interpreters/play-json.html","text":"","title":"Play JSON"},{"location":"/interpreters/play-json.html#play-json","text":"Builds Play JSON Reads and Writes out of JSON schema definitions.\nAPI documentation\nThe JsonSchemas interpreter fixes the JsonSchema[A] type to a type that provides both a Reads[A] and a Writes[A].\nGiven the following type definition:\ncopysourcesealed trait Shape\ncase class Circle(radius: Double) extends Shape\ncase class Rectangle(width: Double, height: Double) extends Shape\nAssuming that there is an implicit JsonSchema[Shape] definition, we can encode a Shape into JSON and decode it using the usual Play JSON operations:\ncopysourceimport JsonSchema._\nval shape: Shape = Circle(42)\nval shapeJson: JsValue = Json.toJson(shape)\nval maybeShape: JsResult[Shape] = Json.fromJson[Shape](shapeJson)","title":"Play JSON"},{"location":"/guides.html","text":"","title":"Guides"},{"location":"/guides.html#guides","text":"This part of the documentation provides in-depth guides for specific features.","title":"Guides"},{"location":"/guides.html#tupler","text":"You might have seen implicit Tupler parameters in the type signature of some algebra operations. The Tupler guide explains what it is used for.","title":"Tupler"},{"location":"/guides.html#extending-endpoints4s-with-application-specific-concepts","text":"When you have application-specific aspects of your communication endpoints that are not covered by endpoints4s you can extend the algebras and their interpreters to include them.\nTypically, each application has its own way of dealing with authentication. The custom authentication guide shows how to enrich the algebras with authentication-related vocabulary and how to extend the client and server interpreters to consistently implement the application-specific authentication mechanism.","title":"Extending endpoints4s with application-specific concepts"},{"location":"/guides/tupler.html","text":"","title":"Tupler"},{"location":"/guides/tupler.html#tupler","text":"This guide explains why we use implicit `Tupler` parameters in the signature of some algebra operations and how it works.","title":"Tupler"},{"location":"/guides/tupler.html#motivation","text":"As explained in the design page, to model a request that carries an information of type A, we use the type Request[A]. This type A is important because it represents what is needed by clients to build such a request and what is received by servers to process such a request. For instance, a request carrying a user id could be modeled as Request[Long]. Clients would have to supply a Long value in order to build such a request, and servers would decode a Long value. Tracking these types is important because it guarantees that requests and responses are well-formed.\nNow, suppose that we define a request that has an URL carrying a user id (of type Long), and an entity carrying an UpdateUser value (describing changes to apply to a user resource). Such a request would have type Request[(Long, UpdateUser)].\nTo support the definition of such requests, the algebra provides an operation that, given an URL and a request entity, returns a request. A naive definition of such an operation could be the following:\ndef request[U, E](url: Url[U], entity: RequestEntity[E]): Request[(U, E)]\nSo that, given an Url[Long] and a RequestEntity[UpdateUser], it would return a Request[(Long, UpdateUser)].\nHowever, some requests have no entity. An empty request entity is modeled by the emptyEntity constructor, which has type RequestEntity[Unit].\nThis means that given the above definition of request, defining a request whose URL carries a Long value, but having no entity, would have type Request[(Long, Unit)]. Also, to build such requests clients would have to supply a (Long, Unit) value, and to handle such requests servers would have to process a (Long, Unit) value. However, these Unit values are never meaningful: they can not carry any useful information.\nThings are even worse because in practice requests are formed of an Url[U], a RequestEntity[E] and a RequestHeaders[H]. So, the “naive” return type of a request should be Request[(U, E, H)], even if several of these type parameters are instantiated to Unit.\nThe goal of the Tupler type is to compute more useful tuple types by discarding the Unit parameters. For instance, it produces a Request[Long] instead of a Request[(Long, Unit)]. Additionally, nested tuples are flattened: Request[((Long, Boolean), String)] becomes Request[(Long, Boolean, String)].","title":"Motivation"},{"location":"/guides/tupler.html#how-it-works","text":"The Tupler[A, B] type takes two type parameters A and B and defines an abstract type member Out. This Out type defines the “useful” form of tupling A and B.\ncopysourcetrait Tupler[A, B] {\n  type Out\n}\nAlgebra operations that want to tuple types A and B take as parameter an implicit tupler: Tupler[A, B] and return a tupler.Out instead of an (A, B).\nSeveral implicit instances of Tupler are provided. For example, the following instance returns a pair of (A, B) for all types A and B:\nimplicit def pair[A, B]: Tupler[A, B] { type Out = (A, B) }\nBut we have seen that our goal is to special case tupling Unit types. This is achieved by defining another Tupler instance with a higher priority than this one, for the case where one of the type parameters is Unit. For instance:\nimplicit def keepFirst[A]: Tupler[A, Unit] { type Out = A }\nThe keepFirst instance computes the type of tupling A and Unit, for all type A, to be A.\nWhen the operation that takes an implicit Tupler as parameter is called, appropriate instances of Tupler will compute the type of the resulting tuple, by discarding Unit types and flattening nested tuples.","title":"How it works"},{"location":"/guides/custom-authentication.html","text":"","title":"Application-specific authentication"},{"location":"/guides/custom-authentication.html#application-specific-authentication","text":"This page explains how to extend the Endpoints algebra with vocabulary specific to the authentication mechanism used by an application, and how to extend interpreters to implement this authentication mechanism for the server side and the client side.\nWe will be using http4s but the same approach can be used for other HTTP libraries.\nWe focus on authentication but the same approach can be used for any other application-specific aspect of the communication that needs to be consistently implemented by clients and servers.","title":"Application-specific authentication"},{"location":"/guides/custom-authentication.html#authentication-flow","text":"In this example, the authentication information will be encoded in a JSON Web Token (JWT) attached to HTTP requests. The client will first login to the server, to get its JWT, and then will use the JWT issued by the server to access to protected resources. This can be summarized by the following diagram:\nWe want to enrich the endpoints4s algebras with new vocabulary describing the login endpoint as well as the protected endpoints.","title":"Authentication flow"},{"location":"/guides/custom-authentication.html#login-endpoint","text":"Let’s start with the login endpoint. This endpoint takes requests containing credentials and returns responses containing the issued JWT, or an empty “Bad Request” response in case the credentials where invalid.","title":"Login endpoint"},{"location":"/guides/custom-authentication.html#authentication-algebra","text":"The existing algebras already provides all we need to describe such an endpoint, except for two things:\nencoding the logged in user information as a JWT in the response, signalling a bad request in case the authentication failed.\nA JWT contains information about the logged-in user (for instance, his name), and that information is serialized and is cryptographically signed by the server (that’s why clients can not forge an arbitrary JWT). In our case, the user information we are interested in is only its name:\ncopysourcecase class UserInfo(name: String)\nThe type used to model the authentication token will be different on client-side and server-side. On server-side, we are only interested in the user info and we want to let the algebra interpreter serialize and sign it. However, on client-side we need to also keep the serialized form since clients can not compute it. Since we want to represent the same concept with different concrete types on the server and client sides, we model it in the algebra with an abstract type member AuthenticationToken.\nIn the end, we need to add the following members to our algebra:\ncopysourceimport endpoints4s.algebra\nimport endpoints4s.Codec\n\n/** Algebra interface for defining authenticated endpoints using JWT.\n  */\ntrait Authentication extends algebra.Endpoints with algebra.JsonEntitiesFromSchemas {\n\n  /** Authentication information. It is left abstract because clients and\n    * servers may want to use different representations\n    */\n  type AuthenticationToken\n\n  /** A response containing a JWT in a JSON document. */\n  final def authenticationToken: Response[AuthenticationToken] = {\n    val authenticationTokenSchema =\n      field[String](\"jwt_token\")\n        .xmapWithCodec(authenticationTokenCodec)\n    ok(jsonResponse(authenticationTokenSchema))\n  }\n\n  /** Logic for decoding the JWT.\n    * Servers validate the token signature, clients just decode without validating.\n    */\n  def authenticationTokenCodec: Codec[String, AuthenticationToken]\n\n  /** A response that might signal to the client that his request was invalid using\n    * a `BadRequest` status.\n    * Clients map `BadRequest` statuses to `None`, and the underlying `response` into `Some`.\n    * Conversely, servers build a `BadRequest` response on `None`, or the underlying `response` otherwise.\n    */\n  final def wheneverValid[A](responseA: Response[A]): Response[Option[A]] =\n    responseA\n      .orElse(response(BadRequest, emptyResponse))\n      .xmap(_.fold[Option[A]](Some(_), _ => None))(_.toLeft(()))\n\n}\nWe define our algebra in a trait named Authentication, which extends the main algebra, algebra.Endpoints.\nGiven this new algebra, we can now describe the login endpoint as follows:\ncopysourceimport endpoints4s.algebra\n\ntrait AuthenticationEndpoints extends algebra.Endpoints with Authentication {\n\n  /** Login endpoint: takes the API key in a query string parameter and returns either `Some(authenticationToken)`\n    * if the credentials are valid, or `None` otherwise\n    */\n  val login: Endpoint[String, Option[AuthenticationToken]] = endpoint(\n    get(path / \"login\" /? qs[String](\"apiKey\")),\n    wheneverValid(authenticationToken)\n  )\n\n}\nThe login endpoint is defined in an AuthenticationTrait, which uses (by inheritance) the main algebra, algebra.Endpoints, and the Authentication algebra.\nThe endpoint takes request using the GET method, the /login URL and a query string parameter apiKey containing the credentials. The returned response is either a “Bad Request”, or a “Ok” with the issued authentication token.","title":"Authentication algebra"},{"location":"/guides/custom-authentication.html#authentication-server-interpreter","text":"The server interpreter fixes the AuthenticationToken type member to UserInfo and implements the authenticationTokenCodec method:\ncopysourceimport endpoints4s.http4s.server\nimport pdi.jwt.JwtCirce\n\ntrait ServerAuthentication[F[_]]\n    extends server.Endpoints[F]\n    with server.JsonEntitiesFromSchemas\n    with Authentication {\n\n  def privateKey: PrivateKey\n  def publicKey: PublicKey\n\n  // On server side, we build the token ourselves so we only care about the user information\n  type AuthenticationToken = UserInfo\n\n  def decodeToken(token: String): Validated[UserInfo] =\n    Validated.fromTry(\n      JwtCirce\n        .decode(token, publicKey)\n        .flatMap { claim =>\n          io.circe.parser.parse(claim.content).toTry.flatMap(_.as[UserInfo].toTry)\n        }\n    )\n\n  // Encodes the user info in the JWT session\n  def authenticationTokenCodec: Codec[String, AuthenticationToken] =\n    Codec.fromEncoderAndDecoder[String, AuthenticationToken] { authenticationToken =>\n      JwtCirce.encode(UserInfo.codec(authenticationToken), privateKey, JwtAlgorithm.RS256)\n    }(decodeToken(_))\n\n}\nThe ServerAuthentication trait extends the Authentication algebra as well as a server Endpoints interpreter based on http4s.\nThe authenticationTokenCodec operation is implemented with the help of the library pauldijou/jwt-scala. It serializes the user info into JSON (via UserInfo.codec), and then creates a signed JWT from it with a private key.\nWith this interpreter, the implementation of the login endpoint looks like the following:\ncopysourceimport endpoints4s.http4s.server\n\nclass Server\n    extends server.Endpoints[IO]\n    with AuthenticationEndpoints\n    with ServerAuthentication[IO] {\n\n    login.implementedBy { apiKey =>\n      if (apiKey == \"foobar\") Some(UserInfo(\"Alice\"))\n      else None\n    }\n\n}\nOur Server class extends the traits that defines the login endpoint, namely the AuthenticationEndpoints, and mixes the http4s-based server interpreter as well as our ServerAuthentication interpreter.\nIn this simplified example, we only have one valid API key, \"foobar\", belonging to Alice. The login endpoint is implemented by a function that checks whether the supplied apiKey is equal to \"foobar\", in which case it returns a UserInfo object wrapped in a Some. Otherwise, it returns None to signal that the API key is invalid.","title":"Authentication server interpreter"},{"location":"/guides/custom-authentication.html#mid-way-summary","text":"What have we learnt so far?\nWe are only halfway through this document but the first sections already showed the key aspects of enriching endpoints4s for application-specific needs:\nWe have enriched the existing algebras with another algebra, by defining a trait extending the existing algebras; We have introduced new concepts as abstract type members (in our case, AuthenticationToken); We have introduced new operations defining how to build or combine concepts together; We have used our algebra to define descriptions of endpoints, by defining a trait extending the algebra; We have implemented an interpreter for our algebra, by defining a trait extending the algebra, mixing an existing base interpreter and implementing the remaining abstract members; We have applied our interpreter to our descriptions of endpoints, by defining a class (or an object) extending the endpoint descriptions and mixing the interpreter trait.\nThese relationships are illustrated by the following diagram:\nThe traits provided by endpoints4s are shown in gray.","title":"Mid-way summary"},{"location":"/guides/custom-authentication.html#authentication-client-interpreter","text":"The implementation of the client interpreter repeats the same recipe: we define a trait ClientAuthentication, which extends Authentication and mixes a client.Endpoints base interpreter:\ncopysourceimport endpoints4s.http4s.client\n\n/** Interpreter for the [[Authentication]] algebra interface that produces\n  * an http4s client (using `org.http4s.client.Client`).\n  */\ntrait ClientAuthentication[F[_]]\n    extends client.Endpoints[F]\n    with client.JsonEntitiesFromSchemas\n    with Authentication {\n\n  def publicKey: PublicKey\n\n  // The constructor is private so that users can not\n  // forge instances themselves\n  class AuthenticationToken private[ClientAuthentication] (\n      private[ClientAuthentication] val token: String,\n      val decoded: UserInfo\n  )\n\n  // Decodes the user info from an OK response\n  def authenticationTokenCodec: Codec[String, AuthenticationToken] =\n    Codec.fromEncoderAndDecoder[String, AuthenticationToken](_.token) { token =>\n      Validated.fromTry(\n        JwtCirce\n          .decode(token, publicKey)\n          .flatMap(claim =>\n            io.circe.parser\n              .parse(claim.content)\n              .toTry\n              .flatMap(\n                _.as[UserInfo].toTry.map(userInfo => new AuthenticationToken(token, userInfo))\n              )\n          )\n      )\n    }\n\n\n}\nThe AuthenticationToken type is implemented as a class whose constructor is private. If it was public, clients could build a fake authentication token which would then fail at runtime because the server would reject it when seeing that it is not correctly signed. By making the constructor private, we make it impossible to reach such a runtime error.\nThe AuthenticationToken class contains the serialized token as well as the decoded UserInfo.\nThe authenticationTokenCodec operation is implemented as the dual of the server interpreter: it tries to decode the JWT, and then tries to parse its content and to decode it as a UserInfo object.\nIn case of failure, it returns an Invalid value, which will ultimately been reported to the user by throwing an exception. One could argue that we should model the fact that decoding the response can fail by returning an Option instead of throwing an exception. However, the philosophy of endpoints4s is that client and server interpreters implement a same HTTP protocol, therefore we expect (and assume) the interpreters to be consistent together. Thus, we assume that don’t need to surface that kind of failures (hence the use of exceptions).\nThis contrasts with the wheneverValid operation, which models the fact that the API key supplied by the user can be invalid. In such a case, we really want the failure to surface to the end-user, hence the usage of Option.","title":"Authentication client interpreter"},{"location":"/guides/custom-authentication.html#putting-things-together-authentication-","text":"If we create an instance of our Client and run our Server, we can test that the following scenarios work as expected:\ncopysource\"wrong login using client\" in {\n  for {\n    loginResult <- client.login.sendAndConsume(\"unknown\")\n  } yield assert(loginResult.isEmpty)\n}\n\"valid login using client\" in {\n  for {\n    loginResult <- client.login.sendAndConsume(\"foobar\")\n  } yield assert(loginResult.nonEmpty)\n}\nThese tests check that if we login with an unknown API key we get no authentication token, but if we login with the \"foobar\" API key then we get some authentication token.","title":"Putting things together (authentication)"},{"location":"/guides/custom-authentication.html#protected-endpoints","text":"Now that we are able to issue an authentication token, let’s see how we can define endpoints that require such an authentication token to be present (and valid) in incoming requests.\nSuch protected endpoints take requests containing the serialized token in their Authorization HTTP header, and return a 401 (Unauthorized) response in case the token is not found or is invalid.","title":"Protected endpoints"},{"location":"/guides/custom-authentication.html#protected-endpoints-algebra","text":"To define protected endpoints, we need to enrich the Authentication algebra with additional vocabulary. First, we need a way to define that requests that must contain the authentication token. Second, we need a way to define that responses might be Unauthorized. Last, we need a convenient Endpoint constructor that puts all the pieces together.\ncopysource/** A request with the given `method`, `url` and `entity`, and which is rejected by the server if it\n  * doesn’t contain a valid JWT.\n  */\nprivate[authentication] def authenticatedRequest[U, E, UE, UET](\n    method: Method,\n    url: Url[U],\n    entity: RequestEntity[E]\n)(implicit\n    tuplerUE: Tupler.Aux[U, E, UE],\n    tuplerUET: Tupler.Aux[UE, AuthenticationToken, UET]\n): Request[UET]\n\n/** A response that might signal to the client that his request was not authenticated.\n  * Clients throw an exception if the response status is `Unauthorized`.\n  * Servers build an `Unauthorized` response in case the incoming request was not correctly authenticated.\n  */\nprivate[authentication] def wheneverAuthenticated[A](\n    response: Response[A]\n): Response[A]\n\n/** User-facing constructor for endpoints requiring authentication.\n  *\n  * @return An endpoint requiring a authentication information to be provided\n  *         in the `Authorization` request header. It returns `response`\n  *         if the request is correctly authenticated, otherwise it returns\n  *         an empty `Unauthorized` response.\n  *\n  * @param method        HTTP method\n  * @param url           Request URL\n  * @param response      HTTP response\n  * @param requestEntity HTTP request entity\n  * @tparam U Information carried by the URL\n  * @tparam E Information carried by the request entity\n  * @tparam R Information carried by the response\n  */\nfinal def authenticatedEndpoint[U, E, R, UE, UET](\n    method: Method,\n    url: Url[U],\n    requestEntity: RequestEntity[E],\n    response: Response[R]\n)(implicit\n    tuplerUE: Tupler.Aux[U, E, UE],\n    tuplerUET: Tupler.Aux[UE, AuthenticationToken, UET]\n): Endpoint[UET, R] =\n  endpoint(\n    authenticatedRequest(method, url, requestEntity),\n    wheneverAuthenticated(response)\n  )\nThe authenticatedRequest method defines a request expecting an authentication token to be provided in the Authorization header. The wheneverAuthenticated method transforms a given Response[A] into another Response[A] that can be an Unauthorized HTTP response in case the client was not authenticated. Note that, in contrast with the previously defined wheneverValid method, we return a Response[A] rather than a Response[Option[A]]. This is because we assume that requests will be built by using the same algebra, which will make them correctly authenticated by construction.\nThe last operation we have introduced is authenticatedEndpoint, which takes a request and a response and wraps the request constituents into the authenticatedRequest constructor, and wraps the response into the wheneverAuthenticated combinator.\nThis authenticatedEndpoint operation is final, and it is the only user-facing operation for defining protected endpoints (the two other operations are private). It guarantees that the request will always have the authentication token in its headers, and that the response can always be Unauthorized.\nNote The authenticatedRequest operation takes several type parameters. In particular, they model the type of the request URL (U) and entity (E). These types must be tracked by the type system so that, eventually, an Endpoint[Req, Resp] is built, where the Req type is a tuple of all the information (URL and entity) carried by the request. In this example we enrich the request headers with the authentication token. However, instead of simply returning nested tuples (e.g. ((U, E), AuthenticationToken)), we rely on implicit Tupler instances to compute the type of the tuple. Tupler instances are defined in a way that always flattens nested tuples (e.g. they will return (U, E, AuthenticationToken)) and removes Unit types (e.g. if the URL is static—of type Url[Unit]—the tuplers return (E, AuthenticationToken)).\nThe authenticatedEndpoint operation can be used as follows:\ncopysource/** Some resource requiring the request to provide a valid JWT token. Returns a message\n  * “Hello ''user_name''” if the request is correctly authenticated, otherwise returns\n  * an `Unauthorized` HTTP response.\n  */\nval someResource: Endpoint[AuthenticationToken, String] =\n  authenticatedEndpoint(\n    Get,\n    path / \"some-resource\",\n    emptyRequest,\n    ok(textResponse)\n  )\nSince the request URL is static and the request has no entity, the information carried by the request is just the AuthenticationToken.","title":"Protected endpoints algebra"},{"location":"/guides/custom-authentication.html#protected-endpoints-server-interpreter","text":"Our http4s-based server is implemented as follows:\ncopysourcedef authenticatedRequest[U, E, UE, UET](\n    method: Method,\n    url: Url[U],\n    entity: RequestEntity[E]\n)(implicit\n    tuplerUE: Tupler.Aux[U, E, UE],\n    tuplerUET: Tupler.Aux[UE, AuthenticationToken, UET]\n): Request[UET] = {\n  // Extracts and validates user info from a request header\n  val authenticationTokenRequestHeaders: RequestHeaders[Option[AuthenticationToken]] = {\n    headers =>\n      {\n        Valid(\n          headers\n            .get[Authorization]\n            .flatMap {\n              case Authorization(Credentials.Token(AuthScheme.Bearer, token)) =>\n                decodeToken(token).toEither.toOption\n              case _ => None\n            }\n        )\n      }\n  }\n\n  new Request[UET] {\n\n    // Data extracted from the incoming request\n    type UrlAndHeaders = (U, AuthenticationToken)\n\n    def matchAndParseHeaders(\n        http4sRequest: org.http4s.Request[F]\n    ): Option[Either[org.http4s.Response[F], Validated[UrlAndHeaders]]] =\n      // First, check whether the incoming request matches this request description\n      matchAndParseHeadersAsRight(method, url, emptyRequestHeaders, http4sRequest)\n        // If this is the case, check whether there is a token in the request headers or not\n        .map { errorResponseOrValidatedUrl =>\n          authenticationTokenRequestHeaders(http4sRequest.headers) match {\n            // There is a token, just add it to the data parsed from the URL\n            case Valid(Some(token)) =>\n              errorResponseOrValidatedUrl\n                .map { validatedUrl =>\n                  validatedUrl.map { case (urlData, _) => (urlData, token) }\n                }\n            // Otherwise, return an Unauthorized response\n            case _ => Left(org.http4s.Response(Unauthorized))\n          }\n        }\n\n    def parseEntity(\n        urlAndHeaders: UrlAndHeaders,\n        http4sRequest: org.http4s.Request[F]\n    ): Effect[Either[org.http4s.Response[F], UET]] =\n      entity(http4sRequest).map(_.map { entityData =>\n        val (urlData, token) = urlAndHeaders\n        tuplerUET(tuplerUE(urlData, entityData), token)\n      })\n\n  }\n}\n\n// Does nothing because `authenticatedReqest` already\n// takes care of returning `Unauthorized` if the request\n// is not properly authenticated\ndef wheneverAuthenticated[A](response: Response[A]): Response[A] = response\nAnd the protected endpoint can be implemented as follows:\ncopysource// Note that the `AuthenticationToken` is available to the implementations\n// It can be used to check authorizations\nsomeResource.implementedBy(token => s\"Hello ${token.name}!\")","title":"Protected endpoints server interpreter"},{"location":"/guides/custom-authentication.html#protected-endpoints-client-interpreter","text":"And our http4s-based client is implemented as follows:\ncopysourcedef authenticatedRequest[U, E, UE, UET](\n    method: Method,\n    url: Url[U],\n    entity: RequestEntity[E]\n)(implicit\n    tuplerUE: Tupler.Aux[U, E, UE],\n    tuplerUET: Tupler.Aux[UE, AuthenticationToken, UET]\n): Request[UET] = {\n  // Encodes the user info as a JWT object in the `Authorization` request header\n  val authenticationTokenRequestHeaders: RequestHeaders[AuthenticationToken] = {\n    (user, http4sRequest) =>\n      http4sRequest.putHeaders(\n        Authorization(Credentials.Token(AuthScheme.Bearer, user.token))\n      )\n  }\n  request(method, url, entity, headers = authenticationTokenRequestHeaders)\n}\n\n// Checks that the response is not `Unauthorized` before continuing\ndef wheneverAuthenticated[A](response: Response[A]): Response[A] = { (status, headers) =>\n  if (status == Unauthorized) {\n    Some(_ => effect.raiseError(new Exception(\"Unauthorized\")))\n  } else {\n    response(status, headers)\n  }\n}","title":"Protected endpoints client interpreter"},{"location":"/guides/custom-authentication.html#putting-things-together-protected-endpoints-","text":"Our Client and Server instances are now able to have more sophisticated exchanges:\ncopysource\"login and access protected resource\" in {\n  for {\n    maybeToken <- client.login.sendAndConsume(\"foobar\")\n    token = maybeToken.get\n    _ = assert(token.decoded == UserInfo(\"Alice\"))\n    resource <- client.someResource.sendAndConsume(token)\n  } yield assert(resource == \"Hello Alice!\")\n}\nThis test first gets an authentication token by calling the login endpoint, and then accesses the protected endpoint by supplying its token.","title":"Putting things together (protected endpoints)"},{"location":"/guides/custom-authentication.html#conclusion","text":"This page shows how to include an application-specific aspect of the communication protocol at the algebra level, and how to implement interpreters for this extended algebra.\nWe only demonstrated how to implement client and server interpreters but the same approach can be used with documentation interpreters.","title":"Conclusion"},{"location":"/community.html","text":"","title":"Community"},{"location":"/community.html#community","text":"","title":"Community"},{"location":"/community.html#discuss","text":"We use a gitter room to announce new releases, to discuss important design decisions, and to answer questions of users.","title":"Discuss"},{"location":"/community.html#related-projects","text":"Here is a list of projects that use endpoints4s.\nscalalandio/endpoints-elm scalalandio/endpoints-json-schemas-macros scalalandio/endpoints-transformer-library twilio/guardrail\nDo you want to add your project to this list? Edit this file and open a pull request!","title":"Related Projects"},{"location":"/community.html#adopters","text":"Here is a list of organizations that use endpoints4s.\nBestmile Rivero\nAre you using endpoints4s? Please consider adding your organization to the list.","title":"Adopters"},{"location":"/comparison.html","text":"","title":"Comparison with similar tools"},{"location":"/comparison.html#comparison-with-similar-tools","text":"In this page, we compare endpoints4s with alternative tools that solve the same problem. We highlights their differences and explain the motivation behind our design decisions.","title":"Comparison with similar tools"},{"location":"/comparison.html#autowire-remotely-lagom-mu","text":"Autowire, and Remotely, and Mu are Scala libraries automating remote procedure calls between a server and a client. Lagom is a framework for implementing microservices.\nThe main difference with endpoints4s is that these tools are based on macros synthesizing the client according to the interface (defined as a Scala trait) of the server. By contrast, endpoints4s uses no macros.\nWe chose not to rely on macros because we find that they make it harder to reason about the code (since they synthesize code that is not seen by the developer), they may not be well supported by IDEs, and they seem to require a significant effort to support all edge cases (several issues have been reported about macro expansion: https://goo.gl/Spco7u, https://goo.gl/F2E5Ev and https://goo.gl/LCmVr8).\nA more fundamental difference is that in Autowire and Remotely, the underlying HTTP communication is viewed as an implementation detail, and all remote calls are multiplexed through a single HTTP endpoint. In contrast, the goal of endpoints4s is to embrace the features of the HTTP protocol (content negotiation, authorization, semantic verbs and status codes, etc.), so, in general, one HTTP endpoint is used for one remote call (though the library also supports multiplexing in case users don’t care about the underlying HTTP protocol).\nLast but not least, Autowire, Remotely, Mu, and Lagom can not generate documentation of the communication protocol.","title":"Autowire / Remotely / Lagom / Mu"},{"location":"/comparison.html#swagger-thrift-grpc","text":"Solutions such as Swagger, Thrift, and gRPC generate the client and server code based on a protocol description written in a custom language, whereas in endpoints4s descriptions are written in plain Scala and producing a client or a server doesn’t require generating code.\nThese custom languages have the benefit of being very clear about their domain, but they generally lack of means of abstraction (no way to factor out similar parts of endpoint descriptions) or means of computing (no expression evaluation, no control structures, etc.). With endpoints4s, developers can easily write a function returning an endpoint description according to some specific logic and given some parameters.\nTools based on code generators have the benefit that they can be integrated with virtually any stack (Scala, Rust, etc.). However, we find that they also have some drawbacks. First, they require users to set up an additional step in their build, ensuring that the code is generated before compiling the modules that use it, and that each time the source files are modified the code is re-generated. Our experience with code generators also showed that sometimes the generated code does not compile. In such a case, it may be difficult to identify the origin of the problem because the error is reported on the generated code, not on the code written by the developer. Furthermore, sometimes the generated code is not convenient to use as it stands, and developers maintain another layer of abstraction on top of it. By not relying on code generation, endpoints4s eliminates these potential problems.\nYou can find a more elaborated article about the limitations of approaches based on code generation in this blog post.","title":"Swagger / Thrift / gRPC"},{"location":"/comparison.html#rho-fintrospect-tapir","text":"Fintrospect, Rho, and tapir projects are comparable alternatives to endpoints4s. Their features and usage are similar: users describe their communication protocol in plain Scala and the library produces clients (Fintrospect and tapir only), servers and documentation.\nA key difference is that in these projects the endpoints description language is defined as a sealed AST: users can not extend descriptions with application-specific concerns and interpreters can not be partial. We can illustrate that point with Web Sockets, a feature that is not be supported by all clients and servers. For instance, Play-WS does not support Web Sockets. This means that a Web Socket endpoint description can not be interpreted by a Play-WS based client. There are two ways to inform the user about such an incompatibility: either by showing a compilation error, or by throwing a runtime exception. In endpoints4s, interpreters can partially support the description language, resulting in a compilation error if one tries to apply an interpreter that is not powerful enough to interpret a given endpoint description. By contrast, if the description language is a sealed AST then all interpreters have to be total, otherwise a MatchError will be thrown at runtime.\nThat being said, a drawback of having an extensible description language is that users have to “build” their language by combining different modules together (eg, Endpoints with JsonEntitiesFromSchemas), and then build matching interpreters. These steps are not needed with projects where the description language is based on a sealed AST.","title":"Rho / Fintrospect / tapir"},{"location":"/comparison.html#servant-typedapi-typed-schema","text":"Servant is a Haskell library that uses generic programming to derive client, server and documentation from endpoint descriptions. typedapi and typed-schema are similar projects written in Scala. In these projects, both descriptions and interpreters are extensible. The difference with endpoints4s is that descriptions are types, whereas in endpoints4s they are values.\nUsing types as descriptions has some benefits: they can directly be used to type instances of data (in contrast, in endpoints4s descriptions of data types have to mirror a corresponding type definition). On the other hand, we believe that abstracting and combining types using type-level computations is, in general, less convenient for users.","title":"Servant / typedapi / typed-schema"},{"location":"/talks.html","text":"","title":"Talks and Articles"},{"location":"/talks.html#talks-and-articles","text":"","title":"Talks and Articles"},{"location":"/talks.html#talks","text":"Endpoints — A quest for the right level of coupling. Scala Italy, 2019. (slides, video) ; Object Algebras and Why You Won’t Touch Http Library Ever Again. Scalar, 2018. (slides, video) ; Using object algebras to design embedded DSLs. Curry On, 2016. (slides, video) ; slides of a talk explaining the motivation and design.","title":"Talks"},{"location":"/talks.html#articles","text":"Modular Remote Communication Protocol Interpreters. Julien Richard-Foy and Wojciech Pituła, 2017. (pdf). RESTful error handling with Akka HTTP and the library endpoints. Julien Richard-Foy and Jonas Chapuis, 2020. Optimistic Concurrency Control in HTTP Services. Julien Richard-Foy, 2020.","title":"Articles"},{"location":"/release-and-compatibility-notes.html","text":"","title":"Release and Compatibility Notes"},{"location":"/release-and-compatibility-notes.html#release-and-compatibility-notes","text":"","title":"Release and Compatibility Notes"},{"location":"/release-and-compatibility-notes.html#binary-compatibility-and-versioning","text":"We follow the recommended versioning scheme for Scala projects:\nall the releases with the same major version number are backward binary compatible, all the releases with the same major and minor version numbers are backward source compatible.\nThe algebra modules and interpreter modules may not follow the same release lifecycles and may have different version numbers.\nYou can find the latest version of each module on scaladex.","title":"Binary Compatibility and Versioning"},{"location":"/release-and-compatibility-notes.html#release-notes","text":"See on GitHub.","title":"Release Notes"}]}